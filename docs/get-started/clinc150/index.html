<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta property="og:title" content="Finetuning a Transformer for Intent Classification" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://finetuner.jina.ai/get-started/clinc150/index.html" />
  <meta property="og:site_name" content="Finetuner 0.4.1 Documentation" />
  <meta property="og:description" content="This example demonstrates how to finetune a model on textual data using finetuner. Specifically we will tune a transformer model on an Intent Classification task. Intent classification is the problem where we try to predict the user intent from a user utterance. It is a common step in chatbots an..." />
  <meta property="og:image" content="https://finetuner.jina.ai/_static/banner.png" />
  <meta property="og:image:alt" content="Finetuner 0.4.1 Documentation" />
  <meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@JinaAI_">
<meta name="twitter:creator" content="@JinaAI_">
<meta name="description" content="Finetuner allows one to finetune any deep neural network for better embedding on search tasks.">
<meta property="og:description" content="Finetuner allows one to finetune any deep neural network for better embedding on search tasks.">

    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-1ESRNDCK35"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-1ESRNDCK35');
</script>
<!-- Place this tag in your head or just before your close body tag. -->
<script async defer src="https://buttons.github.io/buttons.js"></script>
<script async defer src="https://cdn.jsdelivr.net/npm/qabot@0.3"></script>
    <link rel="index" title="Index" href="../../genindex/" /><link rel="search" title="Search" href="../../search/" /><link rel="next" title="Finetuning PointConv on ModelNet40 Dataset" href="../3d-mesh/" /><link rel="prev" title="Finetuning ResNet50 on Totally Looks Like Dataset" href="../totally-looks-like/" />

    <link rel="shortcut icon" href="../../_static/favicon.png"/><meta name="generator" content="sphinx-4.4.0, furo 2022.01.02"/>
        <title>Finetuning a Transformer for Intent Classification - Finetuner 0.4.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?digest=df49af52631e7917044a9c21a57f7b83170a6dd0" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.59c74d8c95b765a7fd995ac71d459ebe.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?digest=fade93df149f7c5fedb3ff897f799dc7d283b420" />
    <link rel="stylesheet" type="text/css" href="../../_static/main.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/docbot.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta2/css/all.min.css" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: #4d4d4d;
  --color-brand-primary: #009191;
  --color-brand-content: #009191;
  
  }
  body[data-theme="dark"] {
    --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #FBCB67;
  --color-brand-content: #FBCB67;
  
  }
  @media (prefers-color-scheme: dark) {
    body:not([data-theme="light"]) {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #FBCB67;
  --color-brand-content: #FBCB67;
  
    }
  }
</style></head>
  <body>
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" />
      <line x1="4" y1="6" x2="20" y2="6" />
      <line x1="10" y1="12" x2="20" y2="12" />
      <line x1="6" y1="18" x2="20" y2="18" />
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
    <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
    <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
    <header class="mobile-header">
        <div class="header-left">
            <label class="nav-overlay-icon" for="__navigation">
                <div class="visually-hidden">Toggle site navigation sidebar</div>
                <i class="icon">
                    <svg>
                        <use href="#svg-menu"></use>
                    </svg>
                </i>
            </label>
        </div>
        <div class="header-center">
            <a href="../../">
                <div class="brand">Finetuner 0.4.1 documentation</div>
            </a>
        </div>
        <div class="header-right">
            <div class="theme-toggle-container theme-toggle-header">
                <button class="theme-toggle">
                    <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
                    <svg class="theme-icon-when-auto">
                        <use href="#svg-sun-half"></use>
                    </svg>
                    <svg class="theme-icon-when-dark">
                        <use href="#svg-moon"></use>
                    </svg>
                    <svg class="theme-icon-when-light">
                        <use href="#svg-sun"></use>
                    </svg>
                </button>
            </div>
            <label class="toc-overlay-icon toc-header-icon" for="__toc">
                <div class="visually-hidden">Toggle table of contents sidebar</div>
                <i class="icon">
                    <svg>
                        <use href="#svg-toc"></use>
                    </svg>
                </i>
            </label>
        </div>
    </header>
    <aside class="sidebar-drawer">
        <div class="sidebar-container">
            
            <div class="sidebar-sticky"><a class="sidebar-brand" href="../../">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../../_static/logo-light.svg" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../../_static/logo-dark.svg" alt="Dark Logo"/>
  </div>
  
  
</a>
<div class="sd-d-flex-row sd-align-major-spaced">
  <a class="github-button" href="https://github.com/jina-ai/finetuner" data-icon="octicon-star" data-show-count="true" aria-label="Star jina-ai/finetuner on GitHub" style="opacity: 0;">Star</a>
  
</div><form class="sidebar-search-container" method="get" action="../../search/" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
    <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../swiss-roll/">Finetuning MLP on Swiss Roll Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../totally-looks-like/">Finetuning ResNet50 on Totally Looks Like Dataset</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Finetuning a Transformer for Intent Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../3d-mesh/">Finetuning PointConv on ModelNet40 Dataset</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../basics/fit/">One-liner <code class="docutils literal notranslate"><span class="pre">fit()</span></code></a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../basics/data-format/">Data Format</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../basics/datasets/class-dataset/">Class Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../basics/datasets/session-dataset/">Session Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../basics/datasets/instance-dataset/">Instance dataset</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../basics/glossary/">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Components</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../components/overview/">Overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../components/tuner/">Tuner</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../components/tuner/loss/">Loss and Miners</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../components/tuner/callbacks/">Callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../components/tuner/evaluation/">Evaluation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../components/tailor/">Tailor</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Reference</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../api/finetuner/">finetuner package</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../api/finetuner.tailor/">finetuner.tailor package</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/finetuner.tailor.keras/">finetuner.tailor.keras package</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tailor.keras.projection_head/">finetuner.tailor.keras.projection_head module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/finetuner.tailor.paddle/">finetuner.tailor.paddle package</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tailor.paddle.projection_head/">finetuner.tailor.paddle.projection_head module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/finetuner.tailor.pytorch/">finetuner.tailor.pytorch package</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tailor.pytorch.projection_head/">finetuner.tailor.pytorch.projection_head module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api/finetuner.tailor.base/">finetuner.tailor.base module</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../api/finetuner.tuner/">finetuner.tuner package</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/finetuner.tuner.callback/">finetuner.tuner.callback package</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.callback.base/">finetuner.tuner.callback.base module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.callback.best_model_checkpoint/">finetuner.tuner.callback.best_model_checkpoint module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.callback.early_stopping/">finetuner.tuner.callback.early_stopping module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.callback.evaluation/">finetuner.tuner.callback.evaluation module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.callback.progress_bar/">finetuner.tuner.callback.progress_bar module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.callback.training_checkpoint/">finetuner.tuner.callback.training_checkpoint module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.callback.wandb_logger/">finetuner.tuner.callback.wandb_logger module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/finetuner.tuner.dataset/">finetuner.tuner.dataset package</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.dataset.base/">finetuner.tuner.dataset.base module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.dataset.datasets/">finetuner.tuner.dataset.datasets module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.dataset.samplers/">finetuner.tuner.dataset.samplers module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/finetuner.tuner.keras/">finetuner.tuner.keras package</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.keras.data/">finetuner.tuner.keras.data module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.keras.losses/">finetuner.tuner.keras.losses module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.keras.miner/">finetuner.tuner.keras.miner module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/finetuner.tuner.miner/">finetuner.tuner.miner package</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.miner.base/">finetuner.tuner.miner.base module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.miner.mining_strategies/">finetuner.tuner.miner.mining_strategies module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/finetuner.tuner.paddle/">finetuner.tuner.paddle package</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.paddle.datasets/">finetuner.tuner.paddle.datasets module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.paddle.losses/">finetuner.tuner.paddle.losses module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.paddle.miner/">finetuner.tuner.paddle.miner module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/finetuner.tuner.pytorch/">finetuner.tuner.pytorch package</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.pytorch.datasets/">finetuner.tuner.pytorch.datasets module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.pytorch.losses/">finetuner.tuner.pytorch.losses module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.pytorch.miner/">finetuner.tuner.pytorch.miner module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api/finetuner.tuner.augmentation/">finetuner.tuner.augmentation module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/finetuner.tuner.base/">finetuner.tuner.base module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/finetuner.tuner.evaluation/">finetuner.tuner.evaluation module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/finetuner.tuner.onnx/">finetuner.tuner.onnx module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/finetuner.tuner.state/">finetuner.tuner.state module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api/finetuner.embedding/">finetuner.embedding module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/finetuner.excepts/">finetuner.excepts module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/finetuner.helper/">finetuner.helper module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/finetuner.toydata/">finetuner.toydata module</a></li>
</ul>
</li>
</ul>

    <p class="caption" role="heading"><span class="caption-text">Ecosystem</span></p>
    <ul>
        <li class="toctree-l1">
            <a class="reference external" href="https://docs.jina.ai">
                <img class="sidebar-ecosys-logo only-light-line" src="../../_static/search-light.svg">
                <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/search-dark.svg">
                Jina</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://hub.jina.ai">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/hub-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/hub-dark.svg">
            Jina Hub</a></li>
        <li class="toctree-l1"><a class="reference internal" href="#">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/finetuner-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/finetuner-dark.svg">
            Finetuner</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://docarray.jina.ai">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/docarray-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/docarray-dark.svg">
            DocArray</a></li>
    </ul>
</div>
</div>
            </div>
            
        </div>
    </aside>
    <div class="main">
        <div class="content">
            <article role="main">
                <div class="content-icon-container">
                    <div class="theme-toggle-container theme-toggle-content">
                        <button class="theme-toggle">
                            <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
                            <svg class="theme-icon-when-auto">
                                <use href="#svg-sun-half"></use>
                            </svg>
                            <svg class="theme-icon-when-dark">
                                <use href="#svg-moon"></use>
                            </svg>
                            <svg class="theme-icon-when-light">
                                <use href="#svg-sun"></use>
                            </svg>
                        </button>
                    </div>
                    <label class="toc-overlay-icon toc-content-icon"
                           for="__toc">
                        <div class="visually-hidden">Toggle table of contents sidebar</div>
                        <i class="icon">
                            <svg>
                                <use href="#svg-toc"></use>
                            </svg>
                        </i>
                    </label>
                </div>
                <section class="tex2jax_ignore mathjax_ignore" id="finetuning-a-transformer-for-intent-classification">
<h1>Finetuning a Transformer for Intent Classification<a class="headerlink" href="#finetuning-a-transformer-for-intent-classification" title="Permalink to this headline">¶</a></h1>
<p>This example demonstrates how to finetune a model on textual data using <code class="docutils literal notranslate"><span class="pre">finetuner</span></code>.
Specifically we will tune a transformer model on an Intent Classification task. Intent
classification is the problem where we try to predict the user intent from a user utterance.
It is a common step in chatbots and Conversational AI, where after the user speech has been
decoded to text, we try to represent the meaning of the text symbolically by predicting
intents and semantic entities. For example:</p>
<ul class="simple">
<li><p>I want to book a flight - intent: <code class="docutils literal notranslate"><span class="pre">book-flight</span></code></p></li>
<li><p>What is the weather forecast for tomorrow? - intent: <code class="docutils literal notranslate"><span class="pre">get-weather</span></code></p></li>
</ul>
<p>The intent classification task is usually formulated as text classification i.e. we build
a classifier to predict intents on input text. In this example, we will formulate
the problem as a search task and use <code class="docutils literal notranslate"><span class="pre">finetuner</span></code> to tune text representations.</p>
<p>We will build an embedding model that embeds text to a high dimensional space and then
we will tune the model so that texts that belong to the same class (intent) are
represented in proximity and texts that belong to separate classes are pulled apart in
our embedding space. To convert our embedding model back to a useful intent prediction
model, we will implement a simple nearest neighbor rule.</p>
<section id="clinc150">
<h2>CLINC150<a class="headerlink" href="#clinc150" title="Permalink to this headline">¶</a></h2>
<p>We will use the CLINC150 dataset as the base of our experiment. It is a dataset of
utterance-intent pairs and is commonly used for evaluating intent models. It comes
in train, val and test splits and contains 150 intents from various chatbot domains.</p>
<p>CLINC150 comes in different sizes with regards to the number of utterances per intent,
to facilitate experimentation on few-shot learning methods. We will use the full version
which includes 100, 20 and 30 utterances per intent in the train, val and test
splits respectively.</p>
<p>For more info on the CLINC150 dataset, check out the
<a class="reference external" href="https://github.com/clinc/oos-eval">dataset repo</a>.</p>
<p>Firstly, let’s dowload the dataset:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl -o data_full.json https://raw.githubusercontent.com/clinc/oos-eval/master/data/data_full.json
</pre></div>
</div>
<p>Let’s look at some examples:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="nt">"examples"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w"></span>
<span class="w">    </span><span class="p">[</span><span class="w"></span>
<span class="w">      </span><span class="s2">"how much is $1 usd in euros"</span><span class="p">,</span><span class="w"> </span>
<span class="w">      </span><span class="s2">"exchange_rate"</span><span class="w"></span>
<span class="w">    </span><span class="p">],</span><span class="w"></span>
<span class="w">    </span><span class="p">[</span><span class="w"></span>
<span class="w">      </span><span class="s2">"what am i listening to right now"</span><span class="p">,</span><span class="w"> </span>
<span class="w">      </span><span class="s2">"what_song"</span><span class="w"></span>
<span class="w">    </span><span class="p">],</span><span class="w"></span>
<span class="w">    </span><span class="p">[</span><span class="w"></span>
<span class="w">      </span><span class="s2">"can you check if meeting rooms are available between 4 and 5"</span><span class="p">,</span><span class="w"> </span>
<span class="w">      </span><span class="s2">"schedule_meeting"</span><span class="w"></span>
<span class="w">    </span><span class="p">],</span><span class="w"> </span>
<span class="w">    </span><span class="p">[</span><span class="w"></span>
<span class="w">      </span><span class="s2">"you know procedure to cook apple pie"</span><span class="p">,</span><span class="w"> </span>
<span class="w">      </span><span class="s2">"recipe"</span><span class="w"></span>
<span class="w">    </span><span class="p">]</span><span class="w"></span>
<span class="w">  </span><span class="p">]</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>The dataset is a JSON file with utterance intent pairs. We convert the train, val and
test splits to <code class="docutils literal notranslate"><span class="pre">DocumentArray</span></code>s and attach the intent label for each doc in
<code class="docutils literal notranslate"><span class="pre">doc.tags['finetuner_label']</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>

<span class="kn">from</span> <span class="nn">docarray</span> <span class="kn">import</span> <span class="n">Document</span><span class="p">,</span> <span class="n">DocumentArray</span>

<span class="n">DATASET_PATH</span> <span class="o">=</span> <span class="s1">'data_full.json'</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">DATASET_PATH</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">DocumentArray</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">Document</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">utterance</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="p">{</span><span class="s1">'finetuner_label'</span><span class="p">:</span> <span class="n">intent</span><span class="p">})</span>
        <span class="k">for</span> <span class="n">utterance</span><span class="p">,</span> <span class="n">intent</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">'train'</span><span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">DocumentArray</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">Document</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">utterance</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="p">{</span><span class="s1">'finetuner_label'</span><span class="p">:</span> <span class="n">intent</span><span class="p">})</span>
        <span class="k">for</span> <span class="n">utterance</span><span class="p">,</span> <span class="n">intent</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">DocumentArray</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">Document</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">utterance</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="p">{</span><span class="s1">'finetuner_label'</span><span class="p">:</span> <span class="n">intent</span><span class="p">})</span>
        <span class="k">for</span> <span class="n">utterance</span><span class="p">,</span> <span class="n">intent</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">'test'</span><span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Num</span> <span class="n">train</span> <span class="n">samples</span><span class="p">:</span> <span class="mi">15000</span>
<span class="n">Num</span> <span class="n">val</span> <span class="n">samples</span><span class="p">:</span> <span class="mi">3000</span>
<span class="n">Num</span> <span class="n">test</span> <span class="n">samples</span><span class="p">:</span> <span class="mi">4500</span>
</pre></div>
</div>
</section>
<section id="embedding-model">
<h2>Embedding model<a class="headerlink" href="#embedding-model" title="Permalink to this headline">¶</a></h2>
<p>As described above, we will use <code class="docutils literal notranslate"><span class="pre">finetuner</span></code> to finetune an embedding model in order
to bring representations of the same intent, closer in the embedding space. For that
we will use the <code class="docutils literal notranslate"><span class="pre">transformers</span></code> library to define a transformer-based embedding model.
We will load a pre-trained transformer as our starting point,
the <a class="reference external" href="https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2">paraphrase-MiniLM-L6-v2</a>
model from <a class="reference external" href="https://www.sbert.net/index.html">sentence-transformers</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span>

<span class="n">TRANSFORMER_MODEL</span> <span class="o">=</span> <span class="s1">'sentence-transformers/paraphrase-MiniLM-L6-v2'</span>

<span class="k">def</span> <span class="nf">mean_pooling</span><span class="p">(</span><span class="n">model_output</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">):</span>
    <span class="n">token_embeddings</span> <span class="o">=</span> <span class="n">model_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">input_mask_expanded</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">attention_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">token_embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">())</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">token_embeddings</span> <span class="o">*</span> <span class="n">input_mask_expanded</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span>
        <span class="n">input_mask_expanded</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-9</span>
    <span class="p">)</span>

<span class="k">class</span> <span class="nc">TransformerEmbedder</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">TRANSFORMER_MODEL</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mean_pooling</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="s1">'attention_mask'</span><span class="p">])</span>
</pre></div>
</div>
<p>Our model is a pre-trained embedding model, i.e. it outputs a high-dimensional
representation given some input text and it has been pre-trained on large text corpora.</p>
<p>To use the model defined above, we need to be able to convert raw text to the tensor
format that our model accepts as input. To do that, we need to use the BPE tokenizer,
provided by the <code class="docutils literal notranslate"><span class="pre">transformers</span></code> package, that converts texts to BPE encoded arrays that
our model accepts as input.</p>
<p>We make use of the collate function that <code class="docutils literal notranslate"><span class="pre">finetuner</span></code> supports. The collate function
offers a way to specify the conversion of batch elements to model input tensors.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>

<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="n">MAX_SEQ_LEN</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">TRANSFORMER_MODEL</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">collate_fn</span><span class="p">(</span><span class="n">inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">inputs</span><span class="p">,</span>
        <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="n">MAX_SEQ_LEN</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="s1">'pt'</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</section>
<section id="fine-tuning">
<h2>Fine-tuning<a class="headerlink" href="#fine-tuning" title="Permalink to this headline">¶</a></h2>
<p>We will finetune the model for 6 epochs using a batch size of 256. We are using a learning
rate of 1e-4, with the AdamW optimizer and a linear learning rate scheduler with warmup.
This weight update strategy is often recommended for finetuning transformer models.
Finetuner allows us to configure the optimizer and the scheduler, via the
<code class="docutils literal notranslate"><span class="pre">configure_optimizer</span></code> argument which should be a function that accepts the model as input
and returns the optimizer and the scheduler as a tuple.</p>
<p>For the training objective, we are using the <code class="docutils literal notranslate"><span class="pre">TripletLoss</span></code> in conjunction with the
<code class="docutils literal notranslate"><span class="pre">TripletEasyHardMiner</span></code> with easy positive and hard negative strategies and a margin of <code class="docutils literal notranslate"><span class="pre">0.4</span></code>.</p>
<p>Finally we make use of the various callbacks provided by <code class="docutils literal notranslate"><span class="pre">finetuner</span></code>, to inject
functionalities in the training loop. Specifically, we use the <code class="docutils literal notranslate"><span class="pre">EvaluationCallback</span></code>
so that metrics are computed on the val set after each epoch, the <code class="docutils literal notranslate"><span class="pre">EarlyStopping</span></code>
callback which monitors the average precision to trigger early stopping if the metric stops
increasing, the <code class="docutils literal notranslate"><span class="pre">BestModelCheckpoint</span></code> that saves the best performing model (in terms of
average precision) every epoch and finally the <code class="docutils literal notranslate"><span class="pre">WandBLogger</span></code> callback that logs our
training information using <a class="reference external" href="https://wandb.ai/site">Weights and Biases</a>.</p>
<p>To use the weights and biases logger, you should install the <code class="docutils literal notranslate"><span class="pre">wandb</span></code> client and login,
provided you have an active account:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install wandb
wandb login
</pre></div>
</div>
<p>Let’s start fine-tuning!</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>

<span class="kn">import</span> <span class="nn">finetuner</span>
<span class="kn">from</span> <span class="nn">finetuner.tuner.callback</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BestModelCheckpoint</span><span class="p">,</span>
    <span class="n">EarlyStopping</span><span class="p">,</span>
    <span class="n">EvaluationCallback</span><span class="p">,</span>
    <span class="n">WandBLogger</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">finetuner.tuner.pytorch.losses</span> <span class="kn">import</span> <span class="n">TripletLoss</span>
<span class="kn">from</span> <span class="nn">finetuner.tuner.pytorch.miner</span> <span class="kn">import</span> <span class="n">TripletEasyHardMiner</span>
<span class="kn">from</span> <span class="nn">transformers.optimization</span> <span class="kn">import</span> <span class="n">get_linear_schedule_with_warmup</span>

<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">NUM_WORKERS</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">NUM_ITEMS_PER_CLASS</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span>

<span class="k">def</span> <span class="nf">configure_optimizer</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">num_training_steps</span><span class="o">=</span><span class="n">EPOCHS</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span> <span class="o">/</span> <span class="n">BATCH_SIZE</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span>

<span class="n">evaluation_callback</span> <span class="o">=</span> <span class="n">EvaluationCallback</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">)</span>
<span class="n">wandb_logger</span> <span class="o">=</span> <span class="n">WandBLogger</span><span class="p">()</span>
<span class="n">early_stopping</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">'average_precision'</span><span class="p">)</span>
<span class="n">best_model_ckpt</span> <span class="o">=</span> <span class="n">BestModelCheckpoint</span><span class="p">(</span>
    <span class="n">save_dir</span><span class="o">=</span><span class="s1">'checkpoints'</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">'average_precision'</span>
<span class="p">)</span>

<span class="n">finetuned_model</span> <span class="o">=</span> <span class="n">finetuner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">TransformerEmbedder</span><span class="p">(),</span>
    <span class="n">train_data</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span>
    <span class="n">eval_data</span><span class="o">=</span><span class="n">val_data</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="n">TripletLoss</span><span class="p">(</span>
        <span class="n">distance</span><span class="o">=</span><span class="s1">'cosine'</span><span class="p">,</span>
        <span class="n">margin</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span>
        <span class="n">miner</span><span class="o">=</span><span class="n">TripletEasyHardMiner</span><span class="p">(</span><span class="n">pos_strategy</span><span class="o">=</span><span class="s1">'easy'</span><span class="p">,</span> <span class="n">neg_strategy</span><span class="o">=</span><span class="s1">'hard'</span><span class="p">),</span>
    <span class="p">),</span>
    <span class="n">configure_optimizer</span><span class="o">=</span><span class="n">configure_optimizer</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">,</span>
    <span class="n">num_items_per_class</span><span class="o">=</span><span class="n">NUM_ITEMS_PER_CLASS</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">evaluation_callback</span><span class="p">,</span> <span class="n">wandb_logger</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">,</span> <span class="n">best_model_ckpt</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Let’s go through the weights and biases run for various training stats. Below is our
learning rate schedule, our training and validation loss and some evaluation metrics
calculcated in our val split:</p>
<figure class="align-default">
<img alt="../../_images/wandb01.png" src="../../_images/wandb01.png"/>
</figure>
<figure class="align-default">
<img alt="../../_images/wandb02.png" src="../../_images/wandb02.png"/>
</figure>
<p>Now it’s time to see how much we improved. To evaluate the model, we can use the
built-in <code class="docutils literal notranslate"><span class="pre">Evaluator</span></code> component of <code class="docutils literal notranslate"><span class="pre">finetuner</span></code> that allows us to compute information
retrieval metrics. We will evaluate both the pre-trained and the fine-tuned model
on the test split of our dataset:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">finetuner.tuner.evaluation</span> <span class="kn">import</span> <span class="n">Evaluator</span>

<span class="n">pretrained_model</span> <span class="o">=</span> <span class="n">TransformerEmbedder</span><span class="p">()</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">embed_model</span><span class="o">=</span><span class="n">pretrained_model</span><span class="p">)</span>
<span class="n">pretrained_metrics</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">limit</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">evaluator</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">embed_model</span><span class="o">=</span><span class="n">finetuned_model</span><span class="p">)</span>
<span class="n">finetuned_metrics</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">limit</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The evaluation metrics are presented in the table below:</p>
<div class="table-wrapper"><table border="1" class="docutils">
<thead>
<tr>
<th align="center">metrics</th>
<th align="center">pre-trained</th>
<th align="center">fine-tuned</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">r_precision</td>
<td align="center">0.660</td>
<td align="center"><strong>0.915</strong></td>
</tr>
<tr>
<td align="center">precision_at_k</td>
<td align="center">0.592</td>
<td align="center"><strong>0.882</strong></td>
</tr>
<tr>
<td align="center">recall_at_k</td>
<td align="center">0.592</td>
<td align="center"><strong>0.882</strong></td>
</tr>
<tr>
<td align="center">f1_score_at_k</td>
<td align="center">0.592</td>
<td align="center"><strong>0.882</strong></td>
</tr>
<tr>
<td align="center">average_precision</td>
<td align="center">0.818</td>
<td align="center"><strong>0.950</strong></td>
</tr>
<tr>
<td align="center">hit_at_k</td>
<td align="center"><strong>0.996</strong></td>
<td align="center">0.992</td>
</tr>
<tr>
<td align="center">reciprocal_rank</td>
<td align="center">0.934</td>
<td align="center"><strong>0.971</strong></td>
</tr>
<tr>
<td align="center">dcg_at_k</td>
<td align="center">6.552</td>
<td align="center"><strong>8.841</strong></td>
</tr>
<tr>
<td align="center">ndcg_at_k</td>
<td align="center">0.909</td>
<td align="center"><strong>0.968</strong></td>
</tr>
</tbody>
</table></div>
<p>The pre-trained model has a solid performance in our dataset. Using <code class="docutils literal notranslate"><span class="pre">finetuner</span></code> though,
we managed to gain a significant improvement in precision, recall and F1 score as
well as DCG and NDCG!</p>
</section>
<section id="back-to-the-classification-task">
<h2>Back to the classification task<a class="headerlink" href="#back-to-the-classification-task" title="Permalink to this headline">¶</a></h2>
<p>We fine-tuned our embedding model and improved significantly in terms of IR metrics.
But how about intent accuracy? How many times do we predict the correct intent? What about
predicting intents in the first place?</p>
<p>In an intent classification task, we want to classify utterances to intents.
So far we formulated the task as a search problem, but to actually use the model
we need to revert back to the classification task. The missing part is a
decision function that can produce intent classes on a test utterance, by
utilising the finetuned embedding model.</p>
<p>A straight-forward way to do that, is to embed the test utterance using our
fine-tuned model and search for the nearest neighbor from a set of utterances
with pre-computed embeddings. This set of utterances with pre-computed
embeddings is usually refered to as the index, and we can use our training
data for it. The class that the nearest neighbor belongs to, will be the class
that we assign to the test utterance.</p>
<p>To go one step further, we can also choose to fetch multiple neighbors
to the test utterance and decide on the intents to return, using a simple rule
that takes into account both the class and the distance of each neighbor.</p>
<p>We implement this function, using <code class="docutils literal notranslate"><span class="pre">docarray</span></code>s <code class="docutils literal notranslate"><span class="pre">match</span></code> and <code class="docutils literal notranslate"><span class="pre">finetuner</span></code>s <code class="docutils literal notranslate"><span class="pre">embed</span></code>
methods.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span>

<span class="kn">from</span> <span class="nn">finetuner</span> <span class="kn">import</span> <span class="n">embed</span>


<span class="k">def</span> <span class="nf">predict_intents</span><span class="p">(</span>
    <span class="n">utterance</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">index</span><span class="p">:</span> <span class="n">DocumentArray</span><span class="p">,</span>
    <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]:</span>
    <span class="sd">"""</span>
<span class="sd">    Find top k nearest neighbors in a search query</span>
<span class="sd">    and compute intents by aggregating distances</span>
<span class="sd">    """</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">Document</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">utterance</span><span class="p">)</span>
    <span class="n">embed</span><span class="p">(</span>
        <span class="n">DocumentArray</span><span class="p">(</span><span class="n">doc</span><span class="p">),</span>
        <span class="n">embed_model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">doc</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>

    <span class="n">intents</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">tags</span><span class="p">[</span><span class="s1">'finetuner_label'</span><span class="p">]</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">matches</span><span class="p">]</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">scores</span><span class="p">[</span><span class="s1">'cosine'</span><span class="p">]</span><span class="o">.</span><span class="n">value</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">matches</span><span class="p">]</span>
    <span class="n">sum_distances</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">dist</span> <span class="o">/</span> <span class="n">sum_distances</span> <span class="k">for</span> <span class="n">dist</span> <span class="ow">in</span> <span class="n">distances</span><span class="p">]</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">intent</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">intents</span><span class="p">,</span> <span class="n">scores</span><span class="p">):</span>
        <span class="n">output</span><span class="p">[</span><span class="n">intent</span><span class="p">]</span> <span class="o">+=</span> <span class="n">score</span>

    <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s index our training data:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>

<span class="n">pretrained_model</span> <span class="o">=</span> <span class="n">TransformerEmbedder</span><span class="p">()</span>

<span class="n">pretrained_index</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">finetuned_index</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>

<span class="n">embed</span><span class="p">(</span>
    <span class="n">pretrained_index</span><span class="p">,</span>
    <span class="n">embed_model</span><span class="o">=</span><span class="n">pretrained_model</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">embed</span><span class="p">(</span>
    <span class="n">finetuned_index</span><span class="p">,</span>
    <span class="n">embed_model</span><span class="o">=</span><span class="n">finetuned_model</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Let’s now use this method to run some test cases.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">utterance</span> <span class="o">=</span> <span class="s1">'Where do you think I should travel to this Christmas?'</span>
<span class="n">intents_pretrained</span> <span class="o">=</span> <span class="n">predict_intents</span><span class="p">(</span><span class="n">utterance</span><span class="p">,</span> <span class="n">pretrained_model</span><span class="p">,</span> <span class="n">pretrained_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">intents_finetuned</span> <span class="o">=</span> <span class="n">predict_intents</span><span class="p">(</span><span class="n">utterance</span><span class="p">,</span> <span class="n">finetuned_model</span><span class="p">,</span> <span class="n">finetuned_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<div class="table-wrapper"><table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p>model <code class="docutils literal notranslate"><span class="pre">k=1</span></code></p></th>
<th class="text-align:center head"><p>Where do you think I should travel to this Christmas?</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p>pre-trained</p></td>
<td class="text-align:center"><p>(‘next_holiday’, 1.0)</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>fine-tuned</p></td>
<td class="text-align:center"><p>(‘travel_suggestion’, 1.0)</p></td>
</tr>
</tbody>
</table></div>
<p>Trying with <code class="docutils literal notranslate"><span class="pre">k=20</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">utterance</span> <span class="o">=</span> <span class="s1">'Where do you think I should travel to this Christmas?'</span>
<span class="n">intents_pretrained</span> <span class="o">=</span> <span class="n">predict_intents</span><span class="p">(</span><span class="n">utterance</span><span class="p">,</span> <span class="n">pretrained_model</span><span class="p">,</span> <span class="n">pretrained_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">intents_finetuned</span> <span class="o">=</span> <span class="n">predict_intents</span><span class="p">(</span><span class="n">utterance</span><span class="p">,</span> <span class="n">finetuned_model</span><span class="p">,</span> <span class="n">finetuned_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
<div class="table-wrapper"><table border="1" class="docutils">
<thead>
<tr>
<th align="center">model <code>k=20</code></th>
<th align="center">Where do you think I should travel to this Christmas?</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">pre-trained</td>
<td align="center">('next_holiday', 0.851), ('travel_suggestion', 0.103), ('spending_history', 0.046)</td>
</tr>
<tr>
<td align="center">fine-tuned</td>
<td align="center">('travel_suggestion', 1.0)</td>
</tr>
</tbody>
</table></div>
<p>What about utterances with 2 intents?</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">utterance</span> <span class="o">=</span> <span class="s1">'What is my location right now? Can you share it with Dave?'</span>
<span class="n">intents_pretrained</span> <span class="o">=</span> <span class="n">predict_intents</span><span class="p">(</span><span class="n">utterance</span><span class="p">,</span> <span class="n">pretrained_model</span><span class="p">,</span> <span class="n">pretrained_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">intents_finetuned</span> <span class="o">=</span> <span class="n">predict_intents</span><span class="p">(</span><span class="n">utterance</span><span class="p">,</span> <span class="n">finetuned_model</span><span class="p">,</span> <span class="n">finetuned_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
<div class="table-wrapper"><table border="1" class="docutils">
<thead>
<tr>
<th align="center">model <code>k=20</code></th>
<th align="center">What is my location right now? Can you share it with Dave?</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">pre-trained</td>
<td align="center">('current_location', 0.628), ('share_location', 0.372)</td>
</tr>
<tr>
<td align="center">fine-tuned</td>
<td align="center">('share_location', 0.745), ('current_location', 0.255)</td>
</tr>
</tbody>
</table></div>
<p>Since we have a way to predict classes in text data, we can evaluate the model
using classification metrics. Let’s try to compare pre-trained and fine-tuned
models in terms of accuracy.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">true_intents</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc</span><span class="o">.</span><span class="n">tags</span><span class="p">[</span><span class="s1">'finetuner_label'</span><span class="p">]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">test_data</span><span class="p">]</span>
<span class="n">pretrained_predicted_intents</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">predict_intents</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">pretrained_model</span><span class="p">,</span> <span class="n">pretrained_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">test_data</span>
<span class="p">]</span>
<span class="n">finetuned_predicted_intents</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">predict_intents</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">finetuned_model</span><span class="p">,</span> <span class="n">finetuned_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">test_data</span>
<span class="p">]</span>

<span class="n">pretrained_acc</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
    <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">t</span> <span class="o">==</span> <span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">true_intents</span><span class="p">,</span> <span class="n">pretrained_predicted_intents</span><span class="p">)]</span>
<span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="n">finetuned_acc</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
    <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">t</span> <span class="o">==</span> <span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">true_intents</span><span class="p">,</span> <span class="n">finetuned_predicted_intents</span><span class="p">)]</span>
<span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</div>
<div class="table-wrapper"><table border="1" class="docutils">
<thead>
<tr>
<th align="center">model <code>k=20</code></th>
<th align="center">accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">pre-trained</td>
<td align="center">0.874</td>
</tr>
<tr>
<td align="center">fine-tuned</td>
<td align="center"><strong>0.946</strong></td>
</tr>
</tbody>
</table></div>
</section>
<section id="full-tutorial">
<h2>Full tutorial<a class="headerlink" href="#full-tutorial" title="Permalink to this headline">¶</a></h2>
<p>For reference, the full tutorial code is given in the snippet below.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Complete source code<div class="sd-summary-down docutils">
<svg aria-hidden="true" class="sd-octicon sd-octicon-chevron-down" height="1.5em" version="1.1" viewbox="0 0 24 24" width="1.5em"><path d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z" fill-rule="evenodd"></path></svg></div>
<div class="sd-summary-up docutils">
<svg aria-hidden="true" class="sd-octicon sd-octicon-chevron-up" height="1.5em" version="1.1" viewbox="0 0 24 24" width="1.5em"><path d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z" fill-rule="evenodd"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">docarray</span> <span class="kn">import</span> <span class="n">Document</span><span class="p">,</span> <span class="n">DocumentArray</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
<span class="kn">from</span> <span class="nn">transformers.optimization</span> <span class="kn">import</span> <span class="n">get_linear_schedule_with_warmup</span>

<span class="kn">import</span> <span class="nn">finetuner</span>
<span class="kn">from</span> <span class="nn">finetuner</span> <span class="kn">import</span> <span class="n">embed</span>
<span class="kn">from</span> <span class="nn">finetuner.tuner.callback</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BestModelCheckpoint</span><span class="p">,</span>
    <span class="n">EarlyStopping</span><span class="p">,</span>
    <span class="n">EvaluationCallback</span><span class="p">,</span>
    <span class="n">WandBLogger</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">finetuner.tuner.evaluation</span> <span class="kn">import</span> <span class="n">Evaluator</span>
<span class="kn">from</span> <span class="nn">finetuner.tuner.pytorch.losses</span> <span class="kn">import</span> <span class="n">TripletLoss</span>
<span class="kn">from</span> <span class="nn">finetuner.tuner.pytorch.miner</span> <span class="kn">import</span> <span class="n">TripletEasyHardMiner</span>


<span class="c1"># ---- DATA ----------------------------------------------------------------------------</span>

<span class="n">DATASET_PATH</span> <span class="o">=</span> <span class="s1">'data_full.json'</span>

<span class="c1"># Load the CLINC150 dataset</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">DATASET_PATH</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="c1"># Load train, val and test data in DocumentArray format</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">DocumentArray</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">Document</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">utterance</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="p">{</span><span class="s1">'finetuner_label'</span><span class="p">:</span> <span class="n">intent</span><span class="p">})</span>
        <span class="k">for</span> <span class="n">utterance</span><span class="p">,</span> <span class="n">intent</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">'train'</span><span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">DocumentArray</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">Document</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">utterance</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="p">{</span><span class="s1">'finetuner_label'</span><span class="p">:</span> <span class="n">intent</span><span class="p">})</span>
        <span class="k">for</span> <span class="n">utterance</span><span class="p">,</span> <span class="n">intent</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">DocumentArray</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">Document</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">utterance</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="p">{</span><span class="s1">'finetuner_label'</span><span class="p">:</span> <span class="n">intent</span><span class="p">})</span>
        <span class="k">for</span> <span class="n">utterance</span><span class="p">,</span> <span class="n">intent</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">'test'</span><span class="p">]</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Num train samples: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Num val samples: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">val_data</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Num test samples: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>


<span class="c1"># ---- MODEL ---------------------------------------------------------------------------</span>

<span class="c1"># Load a transformers model</span>
<span class="c1"># We use sentence-transformers/paraphrase-MiniLM-L6-v2</span>
<span class="c1"># https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2</span>

<span class="n">TRANSFORMER_MODEL</span> <span class="o">=</span> <span class="s1">'sentence-transformers/paraphrase-MiniLM-L6-v2'</span>
<span class="n">MAX_SEQ_LEN</span> <span class="o">=</span> <span class="mi">50</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">TRANSFORMER_MODEL</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">collate_fn</span><span class="p">(</span><span class="n">inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">inputs</span><span class="p">,</span>
        <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="n">MAX_SEQ_LEN</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="s1">'pt'</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">mean_pooling</span><span class="p">(</span><span class="n">model_output</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">):</span>
    <span class="n">token_embeddings</span> <span class="o">=</span> <span class="n">model_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">input_mask_expanded</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">attention_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">token_embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">())</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">token_embeddings</span> <span class="o">*</span> <span class="n">input_mask_expanded</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span>
        <span class="n">input_mask_expanded</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-9</span>
    <span class="p">)</span>


<span class="k">class</span> <span class="nc">TransformerEmbedder</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">TRANSFORMER_MODEL</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mean_pooling</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="s1">'attention_mask'</span><span class="p">])</span>


<span class="c1"># ---- FINE-TUNING ---------------------------------------------------------------------</span>


<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">NUM_WORKERS</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">NUM_ITEMS_PER_CLASS</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span>


<span class="k">def</span> <span class="nf">configure_optimizer</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">num_training_steps</span><span class="o">=</span><span class="n">EPOCHS</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span> <span class="o">/</span> <span class="n">BATCH_SIZE</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span>


<span class="c1"># Let's now run the fine-tuning!</span>
<span class="n">evaluation_callback</span> <span class="o">=</span> <span class="n">EvaluationCallback</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">)</span>
<span class="n">wandb_logger</span> <span class="o">=</span> <span class="n">WandBLogger</span><span class="p">()</span>
<span class="n">early_stopping</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">'average_precision'</span><span class="p">)</span>
<span class="n">best_model_ckpt</span> <span class="o">=</span> <span class="n">BestModelCheckpoint</span><span class="p">(</span>
    <span class="n">save_dir</span><span class="o">=</span><span class="s1">'checkpoints'</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">'average_precision'</span>
<span class="p">)</span>

<span class="n">finetuned_model</span> <span class="o">=</span> <span class="n">finetuner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">TransformerEmbedder</span><span class="p">(),</span>
    <span class="n">train_data</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span>
    <span class="n">eval_data</span><span class="o">=</span><span class="n">val_data</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="n">TripletLoss</span><span class="p">(</span>
        <span class="n">distance</span><span class="o">=</span><span class="s1">'cosine'</span><span class="p">,</span>
        <span class="n">margin</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span>
        <span class="n">miner</span><span class="o">=</span><span class="n">TripletEasyHardMiner</span><span class="p">(</span><span class="n">pos_strategy</span><span class="o">=</span><span class="s1">'easy'</span><span class="p">,</span> <span class="n">neg_strategy</span><span class="o">=</span><span class="s1">'hard'</span><span class="p">),</span>
    <span class="p">),</span>
    <span class="n">configure_optimizer</span><span class="o">=</span><span class="n">configure_optimizer</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">,</span>
    <span class="n">num_items_per_class</span><span class="o">=</span><span class="n">NUM_ITEMS_PER_CLASS</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">evaluation_callback</span><span class="p">,</span> <span class="n">wandb_logger</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">,</span> <span class="n">best_model_ckpt</span><span class="p">],</span>
<span class="p">)</span>

<span class="c1"># Now we will evaluate both pre-trained and fine-tuned models in our test data</span>

<span class="n">pretrained_model</span> <span class="o">=</span> <span class="n">TransformerEmbedder</span><span class="p">()</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">embed_model</span><span class="o">=</span><span class="n">pretrained_model</span><span class="p">)</span>
<span class="n">pretrained_metrics</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">limit</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Evaluating PRE-TRAINED model on test data:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">pretrained_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">()]))</span>

<span class="n">evaluator</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">embed_model</span><span class="o">=</span><span class="n">finetuned_model</span><span class="p">)</span>
<span class="n">finetuned_metrics</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
    <span class="n">limit</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Evaluating FINE-TUNED model on test data:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">finetuned_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">()]))</span>


<span class="c1"># ---- INFERENCE -----------------------------------------------------------------------</span>


<span class="k">def</span> <span class="nf">predict_intents</span><span class="p">(</span>
    <span class="n">utterance</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">index</span><span class="p">:</span> <span class="n">DocumentArray</span><span class="p">,</span>
    <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]:</span>
    <span class="sd">"""</span>
<span class="sd">    Find top k nearest neighbors in a search query</span>
<span class="sd">    and compute intents by aggregating distances</span>
<span class="sd">    """</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">Document</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">utterance</span><span class="p">)</span>
    <span class="n">embed</span><span class="p">(</span>
        <span class="n">DocumentArray</span><span class="p">(</span><span class="n">doc</span><span class="p">),</span>
        <span class="n">embed_model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">doc</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>

    <span class="n">intents</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">tags</span><span class="p">[</span><span class="s1">'finetuner_label'</span><span class="p">]</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">matches</span><span class="p">]</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">scores</span><span class="p">[</span><span class="s1">'cosine'</span><span class="p">]</span><span class="o">.</span><span class="n">value</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">matches</span><span class="p">]</span>
    <span class="n">sum_distances</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">dist</span> <span class="o">/</span> <span class="n">sum_distances</span> <span class="k">for</span> <span class="n">dist</span> <span class="ow">in</span> <span class="n">distances</span><span class="p">]</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">intent</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">intents</span><span class="p">,</span> <span class="n">scores</span><span class="p">):</span>
        <span class="n">output</span><span class="p">[</span><span class="n">intent</span><span class="p">]</span> <span class="o">+=</span> <span class="n">score</span>

    <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># The method above allows us to compute intents on search queries</span>
<span class="c1"># using our embedding model</span>
<span class="c1"># Let's try it out!</span>


<span class="n">pretrained_model</span> <span class="o">=</span> <span class="n">TransformerEmbedder</span><span class="p">()</span>

<span class="c1"># First let's index our data</span>
<span class="n">pretrained_index</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">finetuned_index</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>

<span class="n">embed</span><span class="p">(</span>
    <span class="n">pretrained_index</span><span class="p">,</span>
    <span class="n">embed_model</span><span class="o">=</span><span class="n">pretrained_model</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">embed</span><span class="p">(</span>
    <span class="n">finetuned_index</span><span class="p">,</span>
    <span class="n">embed_model</span><span class="o">=</span><span class="n">finetuned_model</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Let's predict!</span>
<span class="n">utterance</span> <span class="o">=</span> <span class="s1">'Where do you think I should travel to this Christmas?'</span>
<span class="n">intents_pretrained</span> <span class="o">=</span> <span class="n">predict_intents</span><span class="p">(</span><span class="n">utterance</span><span class="p">,</span> <span class="n">pretrained_model</span><span class="p">,</span> <span class="n">pretrained_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">intents_finetuned</span> <span class="o">=</span> <span class="n">predict_intents</span><span class="p">(</span><span class="n">utterance</span><span class="p">,</span> <span class="n">finetuned_model</span><span class="p">,</span> <span class="n">finetuned_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Utterance: </span><span class="si">{</span><span class="n">utterance</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Predicted intents (pre-trained model, k=1): </span><span class="si">{</span><span class="n">intents_pretrained</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Predicted intents (fine-tuned model, k=1): </span><span class="si">{</span><span class="n">intents_finetuned</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># Let's try with k=20</span>
<span class="n">intents_pretrained</span> <span class="o">=</span> <span class="n">predict_intents</span><span class="p">(</span>
    <span class="n">utterance</span><span class="p">,</span> <span class="n">pretrained_model</span><span class="p">,</span> <span class="n">pretrained_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">20</span>
<span class="p">)</span>
<span class="n">intents_finetuned</span> <span class="o">=</span> <span class="n">predict_intents</span><span class="p">(</span><span class="n">utterance</span><span class="p">,</span> <span class="n">finetuned_model</span><span class="p">,</span> <span class="n">finetuned_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Utterance: </span><span class="si">{</span><span class="n">utterance</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Predicted intents (pre-trained model, k=20): </span><span class="si">{</span><span class="n">intents_pretrained</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Predicted intents (fine-tuned model, k=20): </span><span class="si">{</span><span class="n">intents_finetuned</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># How about utterances with two intents?</span>
<span class="n">utterance</span> <span class="o">=</span> <span class="s1">'What is my location right now? Can you share it with Dave?'</span>
<span class="n">intents_pretrained</span> <span class="o">=</span> <span class="n">predict_intents</span><span class="p">(</span>
    <span class="n">utterance</span><span class="p">,</span> <span class="n">pretrained_model</span><span class="p">,</span> <span class="n">pretrained_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">20</span>
<span class="p">)</span>
<span class="n">intents_finetuned</span> <span class="o">=</span> <span class="n">predict_intents</span><span class="p">(</span><span class="n">utterance</span><span class="p">,</span> <span class="n">finetuned_model</span><span class="p">,</span> <span class="n">finetuned_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Utterance: </span><span class="si">{</span><span class="n">utterance</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Predicted intents (pre-trained model, k=20): </span><span class="si">{</span><span class="n">intents_pretrained</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Predicted intents (fine-tuned model, k=20): </span><span class="si">{</span><span class="n">intents_finetuned</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># Since we have a way to predict classes in text data, we can evaluate the model</span>
<span class="c1"># using classification metrics. Let's try to compare pre-trained and fine-tuned</span>
<span class="c1"># models in terms of accuracy</span>

<span class="n">true_intents</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc</span><span class="o">.</span><span class="n">tags</span><span class="p">[</span><span class="s1">'finetuner_label'</span><span class="p">]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">test_data</span><span class="p">]</span>
<span class="n">pretrained_predicted_intents</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">predict_intents</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">pretrained_model</span><span class="p">,</span> <span class="n">pretrained_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">test_data</span>
<span class="p">]</span>
<span class="n">finetuned_predicted_intents</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">predict_intents</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">finetuned_model</span><span class="p">,</span> <span class="n">finetuned_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">test_data</span>
<span class="p">]</span>

<span class="n">pretrained_acc</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
    <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">t</span> <span class="o">==</span> <span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">true_intents</span><span class="p">,</span> <span class="n">pretrained_predicted_intents</span><span class="p">)]</span>
<span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="n">finetuned_acc</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
    <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">t</span> <span class="o">==</span> <span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">true_intents</span><span class="p">,</span> <span class="n">finetuned_predicted_intents</span><span class="p">)]</span>
<span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Pre-trained model accuracy: </span><span class="si">{</span><span class="n">pretrained_acc</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Fine-tuned model accuracy: </span><span class="si">{</span><span class="n">finetuned_acc</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

</pre></div>
</div>
</div>
</details></section>
</section>

            </article>
            <footer>
                
                <div class="related-pages">
                    <a class="next-page" href="../3d-mesh/">
                        <div class="page-info">
                            <div class="context">
                                <span>Next</span>
                            </div>
                            <div class="title">Finetuning PointConv on ModelNet40 Dataset</div>
                        </div>
                        <svg>
                            <use href="#svg-arrow-right"></use>
                        </svg>
                    </a>
                    <a class="prev-page" href="../totally-looks-like/">
                        <svg>
                            <use href="#svg-arrow-right"></use>
                        </svg>
                        <div class="page-info">
                            <div class="context">
                                <span>Previous</span>
                            </div>
                            
                            <div class="title">Finetuning ResNet50 on Totally Looks Like Dataset</div>
                            
                        </div>
                    </a>
                </div>

                <div class="related-information sd-d-inline-flex">
                    <a href="https://jina.ai">Copyright &#169; Jina AI Limited. All rights reserved.</a>
                    Last updated on Feb 08, 2022.
                    <div class="social-btns">
                    <a class='social-btn' href="https://github.com/jina-ai/finetuner/" target="_blank"> <i class="fab fa-github"></i></a>
                    <a class='social-btn' href="https://slack.jina.ai" target="_blank"> <i class="fab fa-slack"></i></a>
                    <a class='social-btn' href="https://youtube.com/c/jina-ai" target="_blank"> <i class="fab fa-youtube"></i></a>
                    <a class='social-btn' href="https://twitter.com/JinaAI_" target="_blank"> <i class="fab fa-twitter"></i></a>
                    <a class='social-btn' href="https://www.linkedin.com/company/jinaai/" target="_blank"> <i class="fab fa-linkedin"></i></a>
                    </div>
                </div>
                
            </footer>
        </div>
        <aside class="toc-drawer">
            

            <div class="toc-sticky toc-scroll">
                
                <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
                </div>
                <div class="toc-tree-container">
                    <div class="toc-tree">
                        <ul>
<li><a class="reference internal" href="#">Finetuning a Transformer for Intent Classification</a><ul>
<li><a class="reference internal" href="#clinc150">CLINC150</a></li>
<li><a class="reference internal" href="#embedding-model">Embedding model</a></li>
<li><a class="reference internal" href="#fine-tuning">Fine-tuning</a></li>
<li><a class="reference internal" href="#back-to-the-classification-task">Back to the classification task</a></li>
<li><a class="reference internal" href="#full-tutorial">Full tutorial</a></li>
</ul>
</li>
</ul>

                    </div>
                </div>
                
                <qa-bot
                    style="position: fixed; width: 15em"
                    theme="follow"
                >
                    <dt>You can ask questions about our docs. Try:</dt>
                    <dd>What is Tailor?</dd>
                    <dd>How can I freeze layers?</dd>
                    <dd>What is the input data format for finetuner?</dd>
                </qa-bot>
            </div>

            
        </aside>

    </div>
</div><script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/scripts/furo.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/tabs.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() { 
            document.querySelector("qa-bot").setAttribute("server", "https://jina-ai-finetuner-docsqa.jina.ai");
        });
        </script>
    </body>
</html>
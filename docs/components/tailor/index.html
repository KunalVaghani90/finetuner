<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta property="og:title" content="Tailor" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://finetuner.jina.ai/components/tailor.html" />
  <meta property="og:site_name" content="Finetuner 0.3.0 Documentation" />
  <meta property="og:description" content="Tailor is a component of Finetuner. It converts any general model into an embedding model. Given a general model (either written from scratch, or from PyTorch/Keras/Huggingface model zoo), Tailor performs micro-operations on the model architecture and outputs an embedding model for the Tuner. Giv..." />
  <meta property="og:image" content="https://finetuner.jina.ai/_static/banner.png" />
  <meta property="og:image:alt" content="Finetuner 0.3.0 Documentation" />
  <meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@JinaAI_">
<meta name="twitter:creator" content="@JinaAI_">
<meta name="description" content="Finetuner allows one to finetune any deep neural network for better embedding on search tasks.">
<meta property="og:description" content="Finetuner allows one to finetune any deep neural network for better embedding on search tasks.">

    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-1ESRNDCK35"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-1ESRNDCK35');
</script>
<!-- Place this tag in your head or just before your close body tag. -->
<script async defer src="https://buttons.github.io/buttons.js"></script>
    <link rel="index" title="Index" href="../../genindex/" /><link rel="search" title="Search" href="../../search/" /><link rel="next" title="Labeler" href="../labeler/" /><link rel="prev" title="Callbacks" href="../tuner/callbacks/" />

    <link rel="shortcut icon" href="../../_static/favicon.png"/><meta name="generator" content="sphinx-4.3.1, furo 2021.11.23"/>
        <title>Tailor - Finetuner 0.3.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?digest=7f0192ddeb2adecfbaa87ffbcf67d16358b30bc1" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.59c74d8c95b765a7fd995ac71d459ebe.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?digest=0af69da206d614734f649b27d4cdc2dd6c31f41d" />
    <link rel="stylesheet" type="text/css" href="../../_static/main.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/docbot.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta2/css/all.min.css" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: #4d4d4d;
  --color-brand-primary: #009191;
  --color-brand-content: #009191;
  
  }
  body[data-theme="dark"] {
    --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #FBCB67;
  --color-brand-content: #FBCB67;
  
  }
  @media (prefers-color-scheme: dark) {
    body:not([data-theme="light"]) {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #FBCB67;
  --color-brand-content: #FBCB67;
  
    }
  }
</style></head>
  <body>
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" />
      <line x1="4" y1="6" x2="20" y2="6" />
      <line x1="10" y1="12" x2="20" y2="12" />
      <line x1="6" y1="18" x2="20" y2="18" />
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
    <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
    <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
    <header class="mobile-header">
        <div class="header-left">
            <label class="nav-overlay-icon" for="__navigation">
                <div class="visually-hidden">Toggle site navigation sidebar</div>
                <i class="icon">
                    <svg>
                        <use href="#svg-menu"></use>
                    </svg>
                </i>
            </label>
        </div>
        <div class="header-center">
            <a href="../../">
                <div class="brand">Finetuner 0.3.0 documentation</div>
            </a>
        </div>
        <div class="header-right">
            <div class="theme-toggle-container theme-toggle-header">
                <button class="theme-toggle">
                    <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
                    <svg class="theme-icon-when-auto">
                        <use href="#svg-sun-half"></use>
                    </svg>
                    <svg class="theme-icon-when-dark">
                        <use href="#svg-moon"></use>
                    </svg>
                    <svg class="theme-icon-when-light">
                        <use href="#svg-sun"></use>
                    </svg>
                </button>
            </div>
            <label class="toc-overlay-icon toc-header-icon" for="__toc">
                <div class="visually-hidden">Toggle table of contents sidebar</div>
                <i class="icon">
                    <svg>
                        <use href="#svg-toc"></use>
                    </svg>
                </i>
            </label>
        </div>
    </header>
    <aside class="sidebar-drawer">
        <div class="sidebar-container">
            
            <div class="sidebar-sticky"><a class="sidebar-brand" href="../../">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../../_static/logo-light.svg" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../../_static/logo-dark.svg" alt="Dark Logo"/>
  </div>
  
  
</a>
<div class="sd-d-flex-row sd-align-major-spaced">
  <a class="github-button" href="https://github.com/jina-ai/finetuner" data-icon="octicon-star" data-show-count="true" aria-label="Star jina-ai/finetuner on GitHub" style="opacity: 0;">Star</a>
  
</div><form class="sidebar-search-container" method="get" action="../../search/" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
    <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../get-started/swiss-roll/">Finetuning MLP on Swiss Roll Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../get-started/fashion-mnist/">Finetuning MLP for Fashion Image Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../get-started/covid-qa/">Finetuning a Transformer for Question-Answering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../get-started/celeba/">Finetuning Pretrained ResNet for Celebrity Face Search</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../basics/fit/">One-liner <code class="docutils literal notranslate"><span class="pre">fit()</span></code></a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../basics/data-format/">Data Format</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../basics/datasets/class-dataset/">Class Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../basics/datasets/session-dataset/">Session Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../basics/datasets/unlabeled-dataset/">Unlabeled Dataset</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../basics/glossary/">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Components</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../overview/">Overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tuner/">Tuner</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tuner/loss/">Loss and Miners</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tuner/callbacks/">Callbacks</a></li>
</ul>
</li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Tailor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../labeler/">Labeler</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Reference</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../api/finetuner/">finetuner package</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../api/finetuner.labeler/">finetuner.labeler package</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api/finetuner.labeler.executor/">finetuner.labeler.executor module</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../api/finetuner.tailor/">finetuner.tailor package</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api/finetuner.tailor.keras/">finetuner.tailor.keras package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/finetuner.tailor.paddle/">finetuner.tailor.paddle package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/finetuner.tailor.pytorch/">finetuner.tailor.pytorch package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/finetuner.tailor.base/">finetuner.tailor.base module</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../api/finetuner.tuner/">finetuner.tuner package</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/finetuner.tuner.callback/">finetuner.tuner.callback package</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.callback.base/">finetuner.tuner.callback.base module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.callback.progress_bar/">finetuner.tuner.callback.progress_bar module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.callback.wandb_logger/">finetuner.tuner.callback.wandb_logger module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/finetuner.tuner.dataset/">finetuner.tuner.dataset package</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.dataset.base/">finetuner.tuner.dataset.base module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.dataset.datasets/">finetuner.tuner.dataset.datasets module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.dataset.samplers/">finetuner.tuner.dataset.samplers module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/finetuner.tuner.keras/">finetuner.tuner.keras package</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.keras.data/">finetuner.tuner.keras.data module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.keras.losses/">finetuner.tuner.keras.losses module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.keras.miner/">finetuner.tuner.keras.miner module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/finetuner.tuner.miner/">finetuner.tuner.miner package</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.miner.base/">finetuner.tuner.miner.base module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.miner.mining_strategies/">finetuner.tuner.miner.mining_strategies module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/finetuner.tuner.paddle/">finetuner.tuner.paddle package</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.paddle.datasets/">finetuner.tuner.paddle.datasets module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.paddle.losses/">finetuner.tuner.paddle.losses module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.paddle.miner/">finetuner.tuner.paddle.miner module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../api/finetuner.tuner.pytorch/">finetuner.tuner.pytorch package</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.pytorch.datasets/">finetuner.tuner.pytorch.datasets module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.pytorch.losses/">finetuner.tuner.pytorch.losses module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api/finetuner.tuner.pytorch.miner/">finetuner.tuner.pytorch.miner module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api/finetuner.tuner.base/">finetuner.tuner.base module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/finetuner.tuner.evaluation/">finetuner.tuner.evaluation module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api/finetuner.tuner.state/">finetuner.tuner.state module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api/finetuner.embedding/">finetuner.embedding module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/finetuner.helper/">finetuner.helper module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/finetuner.toydata/">finetuner.toydata module</a></li>
</ul>
</li>
</ul>

    <p class="caption" role="heading"><span class="caption-text">Ecosystem</span></p>
    <ul>
        <li class="toctree-l1">
            <a class="reference external" href="https://docs.jina.ai">
                <img class="sidebar-ecosys-logo only-light-line" src="../../_static/search-light.svg">
                <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/search-dark.svg">
                Jina</a></li>
        <li class="toctree-l1"><a class="reference external" href="https://hub.jina.ai">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/hub-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/hub-dark.svg">
            Jina Hub</a></li>
        <li class="toctree-l1"><a class="reference internal" href="#">
            <img class="sidebar-ecosys-logo only-light-line" src="../../_static/finetuner-light.svg">
            <img class="sidebar-ecosys-logo only-dark-line" src="../../_static/finetuner-dark.svg">
            Finetuner</a></li>
    </ul>
</div>
</div>
            </div>
            
        </div>
    </aside>
    <div class="main">
        <div class="content">
            <article role="main">
                <div class="content-icon-container">
                    <div class="theme-toggle-container theme-toggle-content">
                        <button class="theme-toggle">
                            <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
                            <svg class="theme-icon-when-auto">
                                <use href="#svg-sun-half"></use>
                            </svg>
                            <svg class="theme-icon-when-dark">
                                <use href="#svg-moon"></use>
                            </svg>
                            <svg class="theme-icon-when-light">
                                <use href="#svg-sun"></use>
                            </svg>
                        </button>
                    </div>
                    <label class="toc-overlay-icon toc-content-icon"
                           for="__toc">
                        <div class="visually-hidden">Toggle table of contents sidebar</div>
                        <i class="icon">
                            <svg>
                                <use href="#svg-toc"></use>
                            </svg>
                        </i>
                    </label>
                </div>
                <section class="tex2jax_ignore mathjax_ignore" id="tailor">
<h1>Tailor<a class="headerlink" href="#tailor" title="Permalink to this headline">¶</a></h1>
<p>Tailor is a component of Finetuner. It converts any <a class="reference internal" href="../../basics/glossary/#term-General-model"><span class="xref std std-term">general model</span></a> into an <a class="reference internal" href="../../basics/glossary/#term-Embedding-model"><span class="xref std std-term">embedding model</span></a>. Given a general model (either written from scratch, or from PyTorch/Keras/Huggingface model zoo), Tailor performs micro-operations on the model architecture and outputs an embedding model for the <a class="reference internal" href="../../basics/glossary/#term-Tuner"><span class="xref std std-term">Tuner</span></a>.</p>
<p>Given a general model with weights, Tailor <em>preserves its weights</em> and performs (some of) the following steps:</p>
<ul class="simple">
<li><p>finding all dense layers by iterating over layers;</p></li>
<li><p>chopping off all layers after a certain dense layer;</p></li>
<li><p>freezing weights of specific layers.</p></li>
<li><p>adding a new bottleneck module on top of the embedding model.</p></li>
</ul>
<figure class="align-center">
<img alt="../../_images/tailor-feature.svg" src="../../_images/tailor-feature.svg"/></figure>
<p>Finally, Tailor outputs an embedding model that can be fine-tuned in Tuner.
To make the best use of Tailor, you could follow the journey of:</p>
<ol class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">display</span></code> model summary.</p></li>
<li><p>Select an embedding layer as your model output.</p></li>
<li><p>Decide your <code class="docutils literal notranslate"><span class="pre">freeze</span></code> strategy.</p></li>
<li><p>(optional) Attach a bottleneck module.</p></li>
</ol>
<section id="display-model-summary">
<h2><code class="docutils literal notranslate"><span class="pre">display</span></code> model summary<a class="headerlink" href="#display-model-summary" title="Permalink to this headline">¶</a></h2>
<p>Tailor provides a helper function <code class="docutils literal notranslate"><span class="pre">finetuner.display()</span></code> that gives a table summary of a Keras/PyTorch/Paddle model.
Let’s see how to create an embedding model with ResNet-50.</p>
<ol>
<li><p>Load a pre-trained ResNet-50 via your favourite deep learning backend and call <code class="docutils literal notranslate"><span class="pre">display</span></code>.</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--0-input--1" name="tab-set--0" type="radio"/><label class="tab-label" for="tab-set--0-input--1">PyTorch</label><div class="tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">finetuner</span> <span class="k">as</span> <span class="nn">ft</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ft</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
</pre></div>
</div>
</div>
<input class="tab-input" id="tab-set--0-input--2" name="tab-set--0" type="radio"/><label class="tab-label" for="tab-set--0-input--2">Keras</label><div class="tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">finetuner</span> <span class="k">as</span> <span class="nn">ft</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">ResNet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">'imagenet'</span><span class="p">)</span>
<span class="n">ft</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input class="tab-input" id="tab-set--0-input--3" name="tab-set--0" type="radio"/><label class="tab-label" for="tab-set--0-input--3">Paddle</label><div class="tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">paddle</span>
<span class="kn">import</span> <span class="nn">finetuner</span> <span class="k">as</span> <span class="nn">ft</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">vision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ft</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</li>
<li><p>Now you could see the model tabular summary in your console/notebook. The summary shows the overall layers, output shapes parameters and trainable layers.</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--1-input--1" name="tab-set--1" type="radio"/><label class="tab-label" for="tab-set--1-input--1">PyTorch</label><div class="tab-content docutils">
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">  name                    output_shape_display   nb_params   trainable  </span>
<span class="go"> ────────────────────────────────────────────────────────────────────── </span>
<span class="go">  conv2d_1                [64, 112, 112]         9408        True       </span>
<span class="go">  batchnorm2d_2           [64, 112, 112]         128         True       </span>
<span class="go">  relu_3                  [64, 112, 112]         0           False      </span>
<span class="go">  maxpool2d_4             [64, 56, 56]           0           False      </span>
<span class="go">  conv2d_5                [64, 56, 56]           4096        True       </span>
<span class="go">  batchnorm2d_6           [64, 56, 56]           128         True       </span>
<span class="go">  relu_7                  [64, 56, 56]           0           False      </span>
<span class="go">  conv2d_8                [64, 56, 56]           36864       True       </span>
<span class="go">  batchnorm2d_9           [64, 56, 56]           128         True       </span>
<span class="go">  relu_10                 [64, 56, 56]           0           False      </span>
<span class="go">  conv2d_11               [256, 56, 56]          16384       True       </span>
<span class="go">  batchnorm2d_12          [256, 56, 56]          512         True       </span>
<span class="go">  conv2d_13               [256, 56, 56]          16384       True       </span>
<span class="go">  batchnorm2d_14          [256, 56, 56]          512         True       </span>
<span class="go">  relu_15                 [256, 56, 56]          0           False      </span>
<span class="go">  bottleneck_16           [256, 56, 56]          0           False      </span>
<span class="go">  conv2d_17               [64, 56, 56]           16384       True       </span>
<span class="go">  batchnorm2d_18          [64, 56, 56]           128         True       </span>
<span class="go">  relu_19                 [64, 56, 56]           0           False      </span>
<span class="go">  conv2d_20               [64, 56, 56]           36864       True       </span>
<span class="go">  batchnorm2d_21          [64, 56, 56]           128         True       </span>
<span class="go">  relu_22                 [64, 56, 56]           0           False      </span>
<span class="go">  conv2d_23               [256, 56, 56]          16384       True       </span>
<span class="go">  batchnorm2d_24          [256, 56, 56]          512         True       </span>
<span class="go">  relu_25                 [256, 56, 56]          0           False      </span>
<span class="go">  bottleneck_26           [256, 56, 56]          0           False      </span>
<span class="go">  conv2d_27               [64, 56, 56]           16384       True       </span>
<span class="go">  batchnorm2d_28          [64, 56, 56]           128         True       </span>
<span class="go">  relu_29                 [64, 56, 56]           0           False      </span>
<span class="go">  conv2d_30               [64, 56, 56]           36864       True       </span>
<span class="go">  batchnorm2d_31          [64, 56, 56]           128         True       </span>
<span class="go">  relu_32                 [64, 56, 56]           0           False      </span>
<span class="go">  conv2d_33               [256, 56, 56]          16384       True       </span>
<span class="go">  batchnorm2d_34          [256, 56, 56]          512         True       </span>
<span class="go">  relu_35                 [256, 56, 56]          0           False      </span>
<span class="go">  bottleneck_36           [256, 56, 56]          0           False      </span>
<span class="go">  conv2d_37               [128, 56, 56]          32768       True       </span>
<span class="go">  batchnorm2d_38          [128, 56, 56]          256         True       </span>
<span class="go">  relu_39                 [128, 56, 56]          0           False      </span>
<span class="go">  conv2d_40               [128, 28, 28]          147456      True       </span>
<span class="go">  batchnorm2d_41          [128, 28, 28]          256         True       </span>
<span class="go">  relu_42                 [128, 28, 28]          0           False      </span>
<span class="go">  conv2d_43               [512, 28, 28]          65536       True       </span>
<span class="go">  batchnorm2d_44          [512, 28, 28]          1024        True       </span>
<span class="go">  conv2d_45               [512, 28, 28]          131072      True       </span>
<span class="go">  batchnorm2d_46          [512, 28, 28]          1024        True       </span>
<span class="go">  relu_47                 [512, 28, 28]          0           False      </span>
<span class="go">  bottleneck_48           [512, 28, 28]          0           False      </span>
<span class="go">  conv2d_49               [128, 28, 28]          65536       True       </span>
<span class="go">  batchnorm2d_50          [128, 28, 28]          256         True       </span>
<span class="go">  relu_51                 [128, 28, 28]          0           False      </span>
<span class="go">  conv2d_52               [128, 28, 28]          147456      True       </span>
<span class="go">  batchnorm2d_53          [128, 28, 28]          256         True       </span>
<span class="go">  relu_54                 [128, 28, 28]          0           False      </span>
<span class="go">  conv2d_55               [512, 28, 28]          65536       True       </span>
<span class="go">  batchnorm2d_56          [512, 28, 28]          1024        True       </span>
<span class="go">  relu_57                 [512, 28, 28]          0           False      </span>
<span class="go">  bottleneck_58           [512, 28, 28]          0           False      </span>
<span class="go">  conv2d_59               [128, 28, 28]          65536       True       </span>
<span class="go">  batchnorm2d_60          [128, 28, 28]          256         True       </span>
<span class="go">  relu_61                 [128, 28, 28]          0           False      </span>
<span class="go">  conv2d_62               [128, 28, 28]          147456      True       </span>
<span class="go">  batchnorm2d_63          [128, 28, 28]          256         True       </span>
<span class="go">  relu_64                 [128, 28, 28]          0           False      </span>
<span class="go">  conv2d_65               [512, 28, 28]          65536       True       </span>
<span class="go">  batchnorm2d_66          [512, 28, 28]          1024        True       </span>
<span class="go">  relu_67                 [512, 28, 28]          0           False      </span>
<span class="go">  bottleneck_68           [512, 28, 28]          0           False      </span>
<span class="go">  conv2d_69               [128, 28, 28]          65536       True       </span>
<span class="go">  batchnorm2d_70          [128, 28, 28]          256         True       </span>
<span class="go">  relu_71                 [128, 28, 28]          0           False      </span>
<span class="go">  conv2d_72               [128, 28, 28]          147456      True       </span>
<span class="go">  batchnorm2d_73          [128, 28, 28]          256         True       </span>
<span class="go">  relu_74                 [128, 28, 28]          0           False      </span>
<span class="go">  conv2d_75               [512, 28, 28]          65536       True       </span>
<span class="go">  batchnorm2d_76          [512, 28, 28]          1024        True       </span>
<span class="go">  relu_77                 [512, 28, 28]          0           False      </span>
<span class="go">  bottleneck_78           [512, 28, 28]          0           False      </span>
<span class="go">  conv2d_79               [256, 28, 28]          131072      True       </span>
<span class="go">  batchnorm2d_80          [256, 28, 28]          512         True       </span>
<span class="go">  relu_81                 [256, 28, 28]          0           False      </span>
<span class="go">  conv2d_82               [256, 14, 14]          589824      True       </span>
<span class="go">  batchnorm2d_83          [256, 14, 14]          512         True       </span>
<span class="go">  relu_84                 [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_85               [1024, 14, 14]         262144      True       </span>
<span class="go">  batchnorm2d_86          [1024, 14, 14]         2048        True       </span>
<span class="go">  conv2d_87               [1024, 14, 14]         524288      True       </span>
<span class="go">  batchnorm2d_88          [1024, 14, 14]         2048        True       </span>
<span class="go">  relu_89                 [1024, 14, 14]         0           False      </span>
<span class="go">  bottleneck_90           [1024, 14, 14]         0           False      </span>
<span class="go">  conv2d_91               [256, 14, 14]          262144      True       </span>
<span class="go">  batchnorm2d_92          [256, 14, 14]          512         True       </span>
<span class="go">  relu_93                 [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_94               [256, 14, 14]          589824      True       </span>
<span class="go">  batchnorm2d_95          [256, 14, 14]          512         True       </span>
<span class="go">  relu_96                 [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_97               [1024, 14, 14]         262144      True       </span>
<span class="go">  batchnorm2d_98          [1024, 14, 14]         2048        True       </span>
<span class="go">  relu_99                 [1024, 14, 14]         0           False      </span>
<span class="go">  bottleneck_100          [1024, 14, 14]         0           False      </span>
<span class="go">  conv2d_101              [256, 14, 14]          262144      True       </span>
<span class="go">  batchnorm2d_102         [256, 14, 14]          512         True       </span>
<span class="go">  relu_103                [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_104              [256, 14, 14]          589824      True       </span>
<span class="go">  batchnorm2d_105         [256, 14, 14]          512         True       </span>
<span class="go">  relu_106                [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_107              [1024, 14, 14]         262144      True       </span>
<span class="go">  batchnorm2d_108         [1024, 14, 14]         2048        True       </span>
<span class="go">  relu_109                [1024, 14, 14]         0           False      </span>
<span class="go">  bottleneck_110          [1024, 14, 14]         0           False      </span>
<span class="go">  conv2d_111              [256, 14, 14]          262144      True       </span>
<span class="go">  batchnorm2d_112         [256, 14, 14]          512         True       </span>
<span class="go">  relu_113                [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_114              [256, 14, 14]          589824      True       </span>
<span class="go">  batchnorm2d_115         [256, 14, 14]          512         True       </span>
<span class="go">  relu_116                [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_117              [1024, 14, 14]         262144      True       </span>
<span class="go">  batchnorm2d_118         [1024, 14, 14]         2048        True       </span>
<span class="go">  relu_119                [1024, 14, 14]         0           False      </span>
<span class="go">  bottleneck_120          [1024, 14, 14]         0           False      </span>
<span class="go">  conv2d_121              [256, 14, 14]          262144      True       </span>
<span class="go">  batchnorm2d_122         [256, 14, 14]          512         True       </span>
<span class="go">  relu_123                [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_124              [256, 14, 14]          589824      True       </span>
<span class="go">  batchnorm2d_125         [256, 14, 14]          512         True       </span>
<span class="go">  relu_126                [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_127              [1024, 14, 14]         262144      True       </span>
<span class="go">  batchnorm2d_128         [1024, 14, 14]         2048        True       </span>
<span class="go">  relu_129                [1024, 14, 14]         0           False      </span>
<span class="go">  bottleneck_130          [1024, 14, 14]         0           False      </span>
<span class="go">  conv2d_131              [256, 14, 14]          262144      True       </span>
<span class="go">  batchnorm2d_132         [256, 14, 14]          512         True       </span>
<span class="go">  relu_133                [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_134              [256, 14, 14]          589824      True       </span>
<span class="go">  batchnorm2d_135         [256, 14, 14]          512         True       </span>
<span class="go">  relu_136                [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_137              [1024, 14, 14]         262144      True       </span>
<span class="go">  batchnorm2d_138         [1024, 14, 14]         2048        True       </span>
<span class="go">  relu_139                [1024, 14, 14]         0           False      </span>
<span class="go">  bottleneck_140          [1024, 14, 14]         0           False      </span>
<span class="go">  conv2d_141              [512, 14, 14]          524288      True       </span>
<span class="go">  batchnorm2d_142         [512, 14, 14]          1024        True       </span>
<span class="go">  relu_143                [512, 14, 14]          0           False      </span>
<span class="go">  conv2d_144              [512, 7, 7]            2359296     True       </span>
<span class="go">  batchnorm2d_145         [512, 7, 7]            1024        True       </span>
<span class="go">  relu_146                [512, 7, 7]            0           False      </span>
<span class="go">  conv2d_147              [2048, 7, 7]           1048576     True       </span>
<span class="go">  batchnorm2d_148         [2048, 7, 7]           4096        True       </span>
<span class="go">  conv2d_149              [2048, 7, 7]           2097152     True       </span>
<span class="go">  batchnorm2d_150         [2048, 7, 7]           4096        True       </span>
<span class="go">  relu_151                [2048, 7, 7]           0           False      </span>
<span class="go">  bottleneck_152          [2048, 7, 7]           0           False      </span>
<span class="go">  conv2d_153              [512, 7, 7]            1048576     True       </span>
<span class="go">  batchnorm2d_154         [512, 7, 7]            1024        True       </span>
<span class="go">  relu_155                [512, 7, 7]            0           False      </span>
<span class="go">  conv2d_156              [512, 7, 7]            2359296     True       </span>
<span class="go">  batchnorm2d_157         [512, 7, 7]            1024        True       </span>
<span class="go">  relu_158                [512, 7, 7]            0           False      </span>
<span class="go">  conv2d_159              [2048, 7, 7]           1048576     True       </span>
<span class="go">  batchnorm2d_160         [2048, 7, 7]           4096        True       </span>
<span class="go">  relu_161                [2048, 7, 7]           0           False      </span>
<span class="go">  bottleneck_162          [2048, 7, 7]           0           False      </span>
<span class="go">  conv2d_163              [512, 7, 7]            1048576     True       </span>
<span class="go">  batchnorm2d_164         [512, 7, 7]            1024        True       </span>
<span class="go">  relu_165                [512, 7, 7]            0           False      </span>
<span class="go">  conv2d_166              [512, 7, 7]            2359296     True       </span>
<span class="go">  batchnorm2d_167         [512, 7, 7]            1024        True       </span>
<span class="go">  relu_168                [512, 7, 7]            0           False      </span>
<span class="go">  conv2d_169              [2048, 7, 7]           1048576     True       </span>
<span class="go">  batchnorm2d_170         [2048, 7, 7]           4096        True       </span>
<span class="go">  relu_171                [2048, 7, 7]           0           False      </span>
<span class="go">  bottleneck_172          [2048, 7, 7]           0           False      </span>
<span class="go">  adaptiveavgpool2d_173   [2048, 1, 1]           0           False      </span>
<span class="go">  linear_174              [1000]                 2049000     True       </span>
<span class="go">                                                                        </span>
<span class="go">Green layers are trainable layers, Cyan layers are non-trainable layers or frozen layers.</span>
<span class="go">Gray layers indicates this layer has been replaced by an Identity layer.</span>
<span class="go">Use to_embedding_model(...) to create embedding model.    </span>
</pre></div>
</div>
</div>
<input class="tab-input" id="tab-set--1-input--2" name="tab-set--1" type="radio"/><label class="tab-label" for="tab-set--1-input--2">Keras</label><div class="tab-content docutils">
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">  name                  output_shape_display   nb_params   trainable  </span>
<span class="go"> ──────────────────────────────────────────────────────────────────── </span>
<span class="go">  input_2               []                     0           False      </span>
<span class="go">  conv1_pad             [230, 230, 3]          0           False      </span>
<span class="go">  conv1_conv            [112, 112, 64]         9472        True       </span>
<span class="go">  conv1_bn              [112, 112, 64]         256         True       </span>
<span class="go">  conv1_relu            [112, 112, 64]         0           False      </span>
<span class="go">  pool1_pad             [114, 114, 64]         0           False      </span>
<span class="go">  pool1_pool            [56, 56, 64]           0           False      </span>
<span class="go">  conv2_block1_1_conv   [56, 56, 64]           4160        True       </span>
<span class="go">  conv2_block1_1_bn     [56, 56, 64]           256         True       </span>
<span class="go">  conv2_block1_1_relu   [56, 56, 64]           0           False      </span>
<span class="go">  conv2_block1_2_conv   [56, 56, 64]           36928       True       </span>
<span class="go">  conv2_block1_2_bn     [56, 56, 64]           256         True       </span>
<span class="go">  conv2_block1_2_relu   [56, 56, 64]           0           False      </span>
<span class="go">  conv2_block1_0_conv   [56, 56, 256]          16640       True       </span>
<span class="go">  conv2_block1_3_conv   [56, 56, 256]          16640       True       </span>
<span class="go">  conv2_block1_0_bn     [56, 56, 256]          1024        True       </span>
<span class="go">  conv2_block1_3_bn     [56, 56, 256]          1024        True       </span>
<span class="go">  conv2_block1_add      [56, 56, 256]          0           False      </span>
<span class="go">  conv2_block1_out      [56, 56, 256]          0           False      </span>
<span class="go">  conv2_block2_1_conv   [56, 56, 64]           16448       True       </span>
<span class="go">  conv2_block2_1_bn     [56, 56, 64]           256         True       </span>
<span class="go">  conv2_block2_1_relu   [56, 56, 64]           0           False      </span>
<span class="go">  conv2_block2_2_conv   [56, 56, 64]           36928       True       </span>
<span class="go">  conv2_block2_2_bn     [56, 56, 64]           256         True       </span>
<span class="go">  conv2_block2_2_relu   [56, 56, 64]           0           False      </span>
<span class="go">  conv2_block2_3_conv   [56, 56, 256]          16640       True       </span>
<span class="go">  conv2_block2_3_bn     [56, 56, 256]          1024        True       </span>
<span class="go">  conv2_block2_add      [56, 56, 256]          0           False      </span>
<span class="go">  conv2_block2_out      [56, 56, 256]          0           False      </span>
<span class="go">  conv2_block3_1_conv   [56, 56, 64]           16448       True       </span>
<span class="go">  conv2_block3_1_bn     [56, 56, 64]           256         True       </span>
<span class="go">  conv2_block3_1_relu   [56, 56, 64]           0           False      </span>
<span class="go">  conv2_block3_2_conv   [56, 56, 64]           36928       True       </span>
<span class="go">  conv2_block3_2_bn     [56, 56, 64]           256         True       </span>
<span class="go">  conv2_block3_2_relu   [56, 56, 64]           0           False      </span>
<span class="go">  conv2_block3_3_conv   [56, 56, 256]          16640       True       </span>
<span class="go">  conv2_block3_3_bn     [56, 56, 256]          1024        True       </span>
<span class="go">  conv2_block3_add      [56, 56, 256]          0           False      </span>
<span class="go">  conv2_block3_out      [56, 56, 256]          0           False      </span>
<span class="go">  conv3_block1_1_conv   [28, 28, 128]          32896       True       </span>
<span class="go">  conv3_block1_1_bn     [28, 28, 128]          512         True       </span>
<span class="go">  conv3_block1_1_relu   [28, 28, 128]          0           False      </span>
<span class="go">  conv3_block1_2_conv   [28, 28, 128]          147584      True       </span>
<span class="go">  conv3_block1_2_bn     [28, 28, 128]          512         True       </span>
<span class="go">  conv3_block1_2_relu   [28, 28, 128]          0           False      </span>
<span class="go">  conv3_block1_0_conv   [28, 28, 512]          131584      True       </span>
<span class="go">  conv3_block1_3_conv   [28, 28, 512]          66048       True       </span>
<span class="go">  conv3_block1_0_bn     [28, 28, 512]          2048        True       </span>
<span class="go">  conv3_block1_3_bn     [28, 28, 512]          2048        True       </span>
<span class="go">  conv3_block1_add      [28, 28, 512]          0           False      </span>
<span class="go">  conv3_block1_out      [28, 28, 512]          0           False      </span>
<span class="go">  conv3_block2_1_conv   [28, 28, 128]          65664       True       </span>
<span class="go">  conv3_block2_1_bn     [28, 28, 128]          512         True       </span>
<span class="go">  conv3_block2_1_relu   [28, 28, 128]          0           False      </span>
<span class="go">  conv3_block2_2_conv   [28, 28, 128]          147584      True       </span>
<span class="go">  conv3_block2_2_bn     [28, 28, 128]          512         True       </span>
<span class="go">  conv3_block2_2_relu   [28, 28, 128]          0           False      </span>
<span class="go">  conv3_block2_3_conv   [28, 28, 512]          66048       True       </span>
<span class="go">  conv3_block2_3_bn     [28, 28, 512]          2048        True       </span>
<span class="go">  conv3_block2_add      [28, 28, 512]          0           False      </span>
<span class="go">  conv3_block2_out      [28, 28, 512]          0           False      </span>
<span class="go">  conv3_block3_1_conv   [28, 28, 128]          65664       True       </span>
<span class="go">  conv3_block3_1_bn     [28, 28, 128]          512         True       </span>
<span class="go">  conv3_block3_1_relu   [28, 28, 128]          0           False      </span>
<span class="go">  conv3_block3_2_conv   [28, 28, 128]          147584      True       </span>
<span class="go">  conv3_block3_2_bn     [28, 28, 128]          512         True       </span>
<span class="go">  conv3_block3_2_relu   [28, 28, 128]          0           False      </span>
<span class="go">  conv3_block3_3_conv   [28, 28, 512]          66048       True       </span>
<span class="go">  conv3_block3_3_bn     [28, 28, 512]          2048        True       </span>
<span class="go">  conv3_block3_add      [28, 28, 512]          0           False      </span>
<span class="go">  conv3_block3_out      [28, 28, 512]          0           False      </span>
<span class="go">  conv3_block4_1_conv   [28, 28, 128]          65664       True       </span>
<span class="go">  conv3_block4_1_bn     [28, 28, 128]          512         True       </span>
<span class="go">  conv3_block4_1_relu   [28, 28, 128]          0           False      </span>
<span class="go">  conv3_block4_2_conv   [28, 28, 128]          147584      True       </span>
<span class="go">  conv3_block4_2_bn     [28, 28, 128]          512         True       </span>
<span class="go">  conv3_block4_2_relu   [28, 28, 128]          0           False      </span>
<span class="go">  conv3_block4_3_conv   [28, 28, 512]          66048       True       </span>
<span class="go">  conv3_block4_3_bn     [28, 28, 512]          2048        True       </span>
<span class="go">  conv3_block4_add      [28, 28, 512]          0           False      </span>
<span class="go">  conv3_block4_out      [28, 28, 512]          0           False      </span>
<span class="go">  conv4_block1_1_conv   [14, 14, 256]          131328      True       </span>
<span class="go">  conv4_block1_1_bn     [14, 14, 256]          1024        True       </span>
<span class="go">  conv4_block1_1_relu   [14, 14, 256]          0           False      </span>
<span class="go">  conv4_block1_2_conv   [14, 14, 256]          590080      True       </span>
<span class="go">  conv4_block1_2_bn     [14, 14, 256]          1024        True       </span>
<span class="go">  conv4_block1_2_relu   [14, 14, 256]          0           False      </span>
<span class="go">  conv4_block1_0_conv   [14, 14, 1024]         525312      True       </span>
<span class="go">  conv4_block1_3_conv   [14, 14, 1024]         263168      True       </span>
<span class="go">  conv4_block1_0_bn     [14, 14, 1024]         4096        True       </span>
<span class="go">  conv4_block1_3_bn     [14, 14, 1024]         4096        True       </span>
<span class="go">  conv4_block1_add      [14, 14, 1024]         0           False      </span>
<span class="go">  conv4_block1_out      [14, 14, 1024]         0           False      </span>
<span class="go">  conv4_block2_1_conv   [14, 14, 256]          262400      True       </span>
<span class="go">  conv4_block2_1_bn     [14, 14, 256]          1024        True       </span>
<span class="go">  conv4_block2_1_relu   [14, 14, 256]          0           False      </span>
<span class="go">  conv4_block2_2_conv   [14, 14, 256]          590080      True       </span>
<span class="go">  conv4_block2_2_bn     [14, 14, 256]          1024        True       </span>
<span class="go">  conv4_block2_2_relu   [14, 14, 256]          0           False      </span>
<span class="go">  conv4_block2_3_conv   [14, 14, 1024]         263168      True       </span>
<span class="go">  conv4_block2_3_bn     [14, 14, 1024]         4096        True       </span>
<span class="go">  conv4_block2_add      [14, 14, 1024]         0           False      </span>
<span class="go">  conv4_block2_out      [14, 14, 1024]         0           False      </span>
<span class="go">  conv4_block3_1_conv   [14, 14, 256]          262400      True       </span>
<span class="go">  conv4_block3_1_bn     [14, 14, 256]          1024        True       </span>
<span class="go">  conv4_block3_1_relu   [14, 14, 256]          0           False      </span>
<span class="go">  conv4_block3_2_conv   [14, 14, 256]          590080      True       </span>
<span class="go">  conv4_block3_2_bn     [14, 14, 256]          1024        True       </span>
<span class="go">  conv4_block3_2_relu   [14, 14, 256]          0           False      </span>
<span class="go">  conv4_block3_3_conv   [14, 14, 1024]         263168      True       </span>
<span class="go">  conv4_block3_3_bn     [14, 14, 1024]         4096        True       </span>
<span class="go">  conv4_block3_add      [14, 14, 1024]         0           False      </span>
<span class="go">  conv4_block3_out      [14, 14, 1024]         0           False      </span>
<span class="go">  conv4_block4_1_conv   [14, 14, 256]          262400      True       </span>
<span class="go">  conv4_block4_1_bn     [14, 14, 256]          1024        True       </span>
<span class="go">  conv4_block4_1_relu   [14, 14, 256]          0           False      </span>
<span class="go">  conv4_block4_2_conv   [14, 14, 256]          590080      True       </span>
<span class="go">  conv4_block4_2_bn     [14, 14, 256]          1024        True       </span>
<span class="go">  conv4_block4_2_relu   [14, 14, 256]          0           False      </span>
<span class="go">  conv4_block4_3_conv   [14, 14, 1024]         263168      True       </span>
<span class="go">  conv4_block4_3_bn     [14, 14, 1024]         4096        True       </span>
<span class="go">  conv4_block4_add      [14, 14, 1024]         0           False      </span>
<span class="go">  conv4_block4_out      [14, 14, 1024]         0           False      </span>
<span class="go">  conv4_block5_1_conv   [14, 14, 256]          262400      True       </span>
<span class="go">  conv4_block5_1_bn     [14, 14, 256]          1024        True       </span>
<span class="go">  conv4_block5_1_relu   [14, 14, 256]          0           False      </span>
<span class="go">  conv4_block5_2_conv   [14, 14, 256]          590080      True       </span>
<span class="go">  conv4_block5_2_bn     [14, 14, 256]          1024        True       </span>
<span class="go">  conv4_block5_2_relu   [14, 14, 256]          0           False      </span>
<span class="go">  conv4_block5_3_conv   [14, 14, 1024]         263168      True       </span>
<span class="go">  conv4_block5_3_bn     [14, 14, 1024]         4096        True       </span>
<span class="go">  conv4_block5_add      [14, 14, 1024]         0           False      </span>
<span class="go">  conv4_block5_out      [14, 14, 1024]         0           False      </span>
<span class="go">  conv4_block6_1_conv   [14, 14, 256]          262400      True       </span>
<span class="go">  conv4_block6_1_bn     [14, 14, 256]          1024        True       </span>
<span class="go">  conv4_block6_1_relu   [14, 14, 256]          0           False      </span>
<span class="go">  conv4_block6_2_conv   [14, 14, 256]          590080      True       </span>
<span class="go">  conv4_block6_2_bn     [14, 14, 256]          1024        True       </span>
<span class="go">  conv4_block6_2_relu   [14, 14, 256]          0           False      </span>
<span class="go">  conv4_block6_3_conv   [14, 14, 1024]         263168      True       </span>
<span class="go">  conv4_block6_3_bn     [14, 14, 1024]         4096        True       </span>
<span class="go">  conv4_block6_add      [14, 14, 1024]         0           False      </span>
<span class="go">  conv4_block6_out      [14, 14, 1024]         0           False      </span>
<span class="go">  conv5_block1_1_conv   [7, 7, 512]            524800      True       </span>
<span class="go">  conv5_block1_1_bn     [7, 7, 512]            2048        True       </span>
<span class="go">  conv5_block1_1_relu   [7, 7, 512]            0           False      </span>
<span class="go">  conv5_block1_2_conv   [7, 7, 512]            2359808     True       </span>
<span class="go">  conv5_block1_2_bn     [7, 7, 512]            2048        True       </span>
<span class="go">  conv5_block1_2_relu   [7, 7, 512]            0           False      </span>
<span class="go">  conv5_block1_0_conv   [7, 7, 2048]           2099200     True       </span>
<span class="go">  conv5_block1_3_conv   [7, 7, 2048]           1050624     True       </span>
<span class="go">  conv5_block1_0_bn     [7, 7, 2048]           8192        True       </span>
<span class="go">  conv5_block1_3_bn     [7, 7, 2048]           8192        True       </span>
<span class="go">  conv5_block1_add      [7, 7, 2048]           0           False      </span>
<span class="go">  conv5_block1_out      [7, 7, 2048]           0           False      </span>
<span class="go">  conv5_block2_1_conv   [7, 7, 512]            1049088     True       </span>
<span class="go">  conv5_block2_1_bn     [7, 7, 512]            2048        True       </span>
<span class="go">  conv5_block2_1_relu   [7, 7, 512]            0           False      </span>
<span class="go">  conv5_block2_2_conv   [7, 7, 512]            2359808     True       </span>
<span class="go">  conv5_block2_2_bn     [7, 7, 512]            2048        True       </span>
<span class="go">  conv5_block2_2_relu   [7, 7, 512]            0           False      </span>
<span class="go">  conv5_block2_3_conv   [7, 7, 2048]           1050624     True       </span>
<span class="go">  conv5_block2_3_bn     [7, 7, 2048]           8192        True       </span>
<span class="go">  conv5_block2_add      [7, 7, 2048]           0           False      </span>
<span class="go">  conv5_block2_out      [7, 7, 2048]           0           False      </span>
<span class="go">  conv5_block3_1_conv   [7, 7, 512]            1049088     True       </span>
<span class="go">  conv5_block3_1_bn     [7, 7, 512]            2048        True       </span>
<span class="go">  conv5_block3_1_relu   [7, 7, 512]            0           False      </span>
<span class="go">  conv5_block3_2_conv   [7, 7, 512]            2359808     True       </span>
<span class="go">  conv5_block3_2_bn     [7, 7, 512]            2048        True       </span>
<span class="go">  conv5_block3_2_relu   [7, 7, 512]            0           False      </span>
<span class="go">  conv5_block3_3_conv   [7, 7, 2048]           1050624     True       </span>
<span class="go">  conv5_block3_3_bn     [7, 7, 2048]           8192        True       </span>
<span class="go">  conv5_block3_add      [7, 7, 2048]           0           False      </span>
<span class="go">  conv5_block3_out      [7, 7, 2048]           0           False      </span>
<span class="go">  avg_pool              [2048]                 0           False      </span>
<span class="go">  predictions           [1000]                 2049000     True       </span>
<span class="go">                                                                      </span>
<span class="go">Green layers are trainable layers, Cyan layers are non-trainable layers or frozen layers.</span>
<span class="go">Gray layers indicates this layer has been replaced by an Identity layer.</span>
<span class="go">Use to_embedding_model(...) to create embedding model.   </span>
</pre></div>
</div>
</div>
<input class="tab-input" id="tab-set--1-input--3" name="tab-set--1" type="radio"/><label class="tab-label" for="tab-set--1-input--3">Paddle</label><div class="tab-content docutils">
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">  name                    output_shape_display   nb_params   trainable  </span>
<span class="go"> ────────────────────────────────────────────────────────────────────── </span>
<span class="go">  conv2d_1                [64, 112, 112]         9408        True       </span>
<span class="go">  batchnorm2d_2           [64, 112, 112]         256         True       </span>
<span class="go">  relu_3                  [64, 112, 112]         0           False      </span>
<span class="go">  maxpool2d_4             [64, 56, 56]           0           False      </span>
<span class="go">  conv2d_5                [64, 56, 56]           4096        True       </span>
<span class="go">  batchnorm2d_6           [64, 56, 56]           256         True       </span>
<span class="go">  relu_7                  [64, 56, 56]           0           False      </span>
<span class="go">  conv2d_8                [64, 56, 56]           36864       True       </span>
<span class="go">  batchnorm2d_9           [64, 56, 56]           256         True       </span>
<span class="go">  relu_10                 [64, 56, 56]           0           False      </span>
<span class="go">  conv2d_11               [256, 56, 56]          16384       True       </span>
<span class="go">  batchnorm2d_12          [256, 56, 56]          1024        True       </span>
<span class="go">  conv2d_13               [256, 56, 56]          16384       True       </span>
<span class="go">  batchnorm2d_14          [256, 56, 56]          1024        True       </span>
<span class="go">  relu_15                 [256, 56, 56]          0           False      </span>
<span class="go">  bottleneckblock_16      [256, 56, 56]          0           False      </span>
<span class="go">  conv2d_17               [64, 56, 56]           16384       True       </span>
<span class="go">  batchnorm2d_18          [64, 56, 56]           256         True       </span>
<span class="go">  relu_19                 [64, 56, 56]           0           False      </span>
<span class="go">  conv2d_20               [64, 56, 56]           36864       True       </span>
<span class="go">  batchnorm2d_21          [64, 56, 56]           256         True       </span>
<span class="go">  relu_22                 [64, 56, 56]           0           False      </span>
<span class="go">  conv2d_23               [256, 56, 56]          16384       True       </span>
<span class="go">  batchnorm2d_24          [256, 56, 56]          1024        True       </span>
<span class="go">  relu_25                 [256, 56, 56]          0           False      </span>
<span class="go">  bottleneckblock_26      [256, 56, 56]          0           False      </span>
<span class="go">  conv2d_27               [64, 56, 56]           16384       True       </span>
<span class="go">  batchnorm2d_28          [64, 56, 56]           256         True       </span>
<span class="go">  relu_29                 [64, 56, 56]           0           False      </span>
<span class="go">  conv2d_30               [64, 56, 56]           36864       True       </span>
<span class="go">  batchnorm2d_31          [64, 56, 56]           256         True       </span>
<span class="go">  relu_32                 [64, 56, 56]           0           False      </span>
<span class="go">  conv2d_33               [256, 56, 56]          16384       True       </span>
<span class="go">  batchnorm2d_34          [256, 56, 56]          1024        True       </span>
<span class="go">  relu_35                 [256, 56, 56]          0           False      </span>
<span class="go">  bottleneckblock_36      [256, 56, 56]          0           False      </span>
<span class="go">  conv2d_37               [128, 56, 56]          32768       True       </span>
<span class="go">  batchnorm2d_38          [128, 56, 56]          512         True       </span>
<span class="go">  relu_39                 [128, 56, 56]          0           False      </span>
<span class="go">  conv2d_40               [128, 28, 28]          147456      True       </span>
<span class="go">  batchnorm2d_41          [128, 28, 28]          512         True       </span>
<span class="go">  relu_42                 [128, 28, 28]          0           False      </span>
<span class="go">  conv2d_43               [512, 28, 28]          65536       True       </span>
<span class="go">  batchnorm2d_44          [512, 28, 28]          2048        True       </span>
<span class="go">  conv2d_45               [512, 28, 28]          131072      True       </span>
<span class="go">  batchnorm2d_46          [512, 28, 28]          2048        True       </span>
<span class="go">  relu_47                 [512, 28, 28]          0           False      </span>
<span class="go">  bottleneckblock_48      [512, 28, 28]          0           False      </span>
<span class="go">  conv2d_49               [128, 28, 28]          65536       True       </span>
<span class="go">  batchnorm2d_50          [128, 28, 28]          512         True       </span>
<span class="go">  relu_51                 [128, 28, 28]          0           False      </span>
<span class="go">  conv2d_52               [128, 28, 28]          147456      True       </span>
<span class="go">  batchnorm2d_53          [128, 28, 28]          512         True       </span>
<span class="go">  relu_54                 [128, 28, 28]          0           False      </span>
<span class="go">  conv2d_55               [512, 28, 28]          65536       True       </span>
<span class="go">  batchnorm2d_56          [512, 28, 28]          2048        True       </span>
<span class="go">  relu_57                 [512, 28, 28]          0           False      </span>
<span class="go">  bottleneckblock_58      [512, 28, 28]          0           False      </span>
<span class="go">  conv2d_59               [128, 28, 28]          65536       True       </span>
<span class="go">  batchnorm2d_60          [128, 28, 28]          512         True       </span>
<span class="go">  relu_61                 [128, 28, 28]          0           False      </span>
<span class="go">  conv2d_62               [128, 28, 28]          147456      True       </span>
<span class="go">  batchnorm2d_63          [128, 28, 28]          512         True       </span>
<span class="go">  relu_64                 [128, 28, 28]          0           False      </span>
<span class="go">  conv2d_65               [512, 28, 28]          65536       True       </span>
<span class="go">  batchnorm2d_66          [512, 28, 28]          2048        True       </span>
<span class="go">  relu_67                 [512, 28, 28]          0           False      </span>
<span class="go">  bottleneckblock_68      [512, 28, 28]          0           False      </span>
<span class="go">  conv2d_69               [128, 28, 28]          65536       True       </span>
<span class="go">  batchnorm2d_70          [128, 28, 28]          512         True       </span>
<span class="go">  relu_71                 [128, 28, 28]          0           False      </span>
<span class="go">  conv2d_72               [128, 28, 28]          147456      True       </span>
<span class="go">  batchnorm2d_73          [128, 28, 28]          512         True       </span>
<span class="go">  relu_74                 [128, 28, 28]          0           False      </span>
<span class="go">  conv2d_75               [512, 28, 28]          65536       True       </span>
<span class="go">  batchnorm2d_76          [512, 28, 28]          2048        True       </span>
<span class="go">  relu_77                 [512, 28, 28]          0           False      </span>
<span class="go">  bottleneckblock_78      [512, 28, 28]          0           False      </span>
<span class="go">  conv2d_79               [256, 28, 28]          131072      True       </span>
<span class="go">  batchnorm2d_80          [256, 28, 28]          1024        True       </span>
<span class="go">  relu_81                 [256, 28, 28]          0           False      </span>
<span class="go">  conv2d_82               [256, 14, 14]          589824      True       </span>
<span class="go">  batchnorm2d_83          [256, 14, 14]          1024        True       </span>
<span class="go">  relu_84                 [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_85               [1024, 14, 14]         262144      True       </span>
<span class="go">  batchnorm2d_86          [1024, 14, 14]         4096        True       </span>
<span class="go">  conv2d_87               [1024, 14, 14]         524288      True       </span>
<span class="go">  batchnorm2d_88          [1024, 14, 14]         4096        True       </span>
<span class="go">  relu_89                 [1024, 14, 14]         0           False      </span>
<span class="go">  bottleneckblock_90      [1024, 14, 14]         0           False      </span>
<span class="go">  conv2d_91               [256, 14, 14]          262144      True       </span>
<span class="go">  batchnorm2d_92          [256, 14, 14]          1024        True       </span>
<span class="go">  relu_93                 [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_94               [256, 14, 14]          589824      True       </span>
<span class="go">  batchnorm2d_95          [256, 14, 14]          1024        True       </span>
<span class="go">  relu_96                 [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_97               [1024, 14, 14]         262144      True       </span>
<span class="go">  batchnorm2d_98          [1024, 14, 14]         4096        True       </span>
<span class="go">  relu_99                 [1024, 14, 14]         0           False      </span>
<span class="go">  bottleneckblock_100     [1024, 14, 14]         0           False      </span>
<span class="go">  conv2d_101              [256, 14, 14]          262144      True       </span>
<span class="go">  batchnorm2d_102         [256, 14, 14]          1024        True       </span>
<span class="go">  relu_103                [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_104              [256, 14, 14]          589824      True       </span>
<span class="go">  batchnorm2d_105         [256, 14, 14]          1024        True       </span>
<span class="go">  relu_106                [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_107              [1024, 14, 14]         262144      True       </span>
<span class="go">  batchnorm2d_108         [1024, 14, 14]         4096        True       </span>
<span class="go">  relu_109                [1024, 14, 14]         0           False      </span>
<span class="go">  bottleneckblock_110     [1024, 14, 14]         0           False      </span>
<span class="go">  conv2d_111              [256, 14, 14]          262144      True       </span>
<span class="go">  batchnorm2d_112         [256, 14, 14]          1024        True       </span>
<span class="go">  relu_113                [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_114              [256, 14, 14]          589824      True       </span>
<span class="go">  batchnorm2d_115         [256, 14, 14]          1024        True       </span>
<span class="go">  relu_116                [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_117              [1024, 14, 14]         262144      True       </span>
<span class="go">  batchnorm2d_118         [1024, 14, 14]         4096        True       </span>
<span class="go">  relu_119                [1024, 14, 14]         0           False      </span>
<span class="go">  bottleneckblock_120     [1024, 14, 14]         0           False      </span>
<span class="go">  conv2d_121              [256, 14, 14]          262144      True       </span>
<span class="go">  batchnorm2d_122         [256, 14, 14]          1024        True       </span>
<span class="go">  relu_123                [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_124              [256, 14, 14]          589824      True       </span>
<span class="go">  batchnorm2d_125         [256, 14, 14]          1024        True       </span>
<span class="go">  relu_126                [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_127              [1024, 14, 14]         262144      True       </span>
<span class="go">  batchnorm2d_128         [1024, 14, 14]         4096        True       </span>
<span class="go">  relu_129                [1024, 14, 14]         0           False      </span>
<span class="go">  bottleneckblock_130     [1024, 14, 14]         0           False      </span>
<span class="go">  conv2d_131              [256, 14, 14]          262144      True       </span>
<span class="go">  batchnorm2d_132         [256, 14, 14]          1024        True       </span>
<span class="go">  relu_133                [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_134              [256, 14, 14]          589824      True       </span>
<span class="go">  batchnorm2d_135         [256, 14, 14]          1024        True       </span>
<span class="go">  relu_136                [256, 14, 14]          0           False      </span>
<span class="go">  conv2d_137              [1024, 14, 14]         262144      True       </span>
<span class="go">  batchnorm2d_138         [1024, 14, 14]         4096        True       </span>
<span class="go">  relu_139                [1024, 14, 14]         0           False      </span>
<span class="go">  bottleneckblock_140     [1024, 14, 14]         0           False      </span>
<span class="go">  conv2d_141              [512, 14, 14]          524288      True       </span>
<span class="go">  batchnorm2d_142         [512, 14, 14]          2048        True       </span>
<span class="go">  relu_143                [512, 14, 14]          0           False      </span>
<span class="go">  conv2d_144              [512, 7, 7]            2359296     True       </span>
<span class="go">  batchnorm2d_145         [512, 7, 7]            2048        True       </span>
<span class="go">  relu_146                [512, 7, 7]            0           False      </span>
<span class="go">  conv2d_147              [2048, 7, 7]           1048576     True       </span>
<span class="go">  batchnorm2d_148         [2048, 7, 7]           8192        True       </span>
<span class="go">  conv2d_149              [2048, 7, 7]           2097152     True       </span>
<span class="go">  batchnorm2d_150         [2048, 7, 7]           8192        True       </span>
<span class="go">  relu_151                [2048, 7, 7]           0           False      </span>
<span class="go">  bottleneckblock_152     [2048, 7, 7]           0           False      </span>
<span class="go">  conv2d_153              [512, 7, 7]            1048576     True       </span>
<span class="go">  batchnorm2d_154         [512, 7, 7]            2048        True       </span>
<span class="go">  relu_155                [512, 7, 7]            0           False      </span>
<span class="go">  conv2d_156              [512, 7, 7]            2359296     True       </span>
<span class="go">  batchnorm2d_157         [512, 7, 7]            2048        True       </span>
<span class="go">  relu_158                [512, 7, 7]            0           False      </span>
<span class="go">  conv2d_159              [2048, 7, 7]           1048576     True       </span>
<span class="go">  batchnorm2d_160         [2048, 7, 7]           8192        True       </span>
<span class="go">  relu_161                [2048, 7, 7]           0           False      </span>
<span class="go">  bottleneckblock_162     [2048, 7, 7]           0           False      </span>
<span class="go">  conv2d_163              [512, 7, 7]            1048576     True       </span>
<span class="go">  batchnorm2d_164         [512, 7, 7]            2048        True       </span>
<span class="go">  relu_165                [512, 7, 7]            0           False      </span>
<span class="go">  conv2d_166              [512, 7, 7]            2359296     True       </span>
<span class="go">  batchnorm2d_167         [512, 7, 7]            2048        True       </span>
<span class="go">  relu_168                [512, 7, 7]            0           False      </span>
<span class="go">  conv2d_169              [2048, 7, 7]           1048576     True       </span>
<span class="go">  batchnorm2d_170         [2048, 7, 7]           8192        True       </span>
<span class="go">  relu_171                [2048, 7, 7]           0           False      </span>
<span class="go">  bottleneckblock_172     [2048, 7, 7]           0           False      </span>
<span class="go">  adaptiveavgpool2d_173   [2048, 1, 1]           0           False      </span>
<span class="go">  linear_174              [1000]                 2049000     True       </span>
<span class="go">                                                                        </span>
<span class="go">Green layers are trainable layers, Cyan layers are non-trainable layers or frozen layers.</span>
<span class="go">Gray layers indicates this layer has been replaced by an Identity layer.</span>
<span class="go">Use to_embedding_model(...) to create embedding model.    </span>
</pre></div>
</div>
</div>
</div>
</li>
</ol>
</section>
<section id="select-an-embedding-layer-as-your-model-output">
<h2>Select an embedding layer as your model output.<a class="headerlink" href="#select-an-embedding-layer-as-your-model-output" title="Permalink to this headline">¶</a></h2>
<p>After plotted the table summary of the pre-trained model, we can decide which layer can be used as the “embedding layer”.
As you can see in the above ResNet-50, layer with name <code class="docutils literal notranslate"><span class="pre">linear_174</span></code> (pytorch/paddle) or <code class="docutils literal notranslate"><span class="pre">predictions</span></code> (keras) is the final classification layer for classify 1000 ImageNet classes.
This layer is not a good chocie of “embedding layer”. We’ll use <code class="docutils literal notranslate"><span class="pre">adaptiveavgpool2d_173</span></code> (pytorch/paddle) or <code class="docutils literal notranslate"><span class="pre">avg_pool</span></code> (keras) as our “embedding layer”.</p>
<p>Keep the layer name in mind, we’ll put everything together after we decide <code class="docutils literal notranslate"><span class="pre">freeze</span></code> strategy and <code class="docutils literal notranslate"><span class="pre">bottleneck</span> <span class="pre">layer</span></code>.</p>
</section>
<section id="decide-your-freeze-strategy">
<h2>Decide your <code class="docutils literal notranslate"><span class="pre">freeze</span></code> strategy.<a class="headerlink" href="#decide-your-freeze-strategy" title="Permalink to this headline">¶</a></h2>
<p>To apply a pre-trained model on your downstream task, in most cases you do not want to train everything from scratch.
Finetuner allows you to freeze the entire model or freeze specific layers, with <code class="docutils literal notranslate"><span class="pre">freeze</span></code> argument.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">freeze=True</span></code>, finetuner will freeze the entire pre-trained model. If freeze is a list of string layer names,
for example, <code class="docutils literal notranslate"><span class="pre">freeze=['conv2d_1',</span> <span class="pre">'conv2d_5']</span></code> will only freeze these two layers.</p>
<p>Again, keep this in mind, we’ll put everything together after we attach the <code class="docutils literal notranslate"><span class="pre">bottleneck</span> <span class="pre">layer</span></code>.</p>
</section>
<section id="optional-attach-a-bottleneck-module">
<h2>(optional) Attach a bottleneck module.<a class="headerlink" href="#optional-attach-a-bottleneck-module" title="Permalink to this headline">¶</a></h2>
<p>Sometimes you want to add a bottleneck module or projection head on top of your embedding model.
This bottleneck layer should be a simple multi-layer perceptron.
This could help you improve your embedding quality and potentially reduce the dimensionality.</p>
<p>Tailor allows you to attach this small bottleneck module on top of your embedding model.
In the below example, we put everything together, including:</p>
<ul class="simple">
<li><p>choose embedding layer</p></li>
<li><p>freezing weights of specific layers.</p></li>
<li><p>attach a bottleneck layer</p></li>
</ul>
<p>with the method called <code class="docutils literal notranslate"><span class="pre">to_embedding_model</span></code> method.</p>
<ol>
<li><p>Tailor provides a high-level API <code class="docutils literal notranslate"><span class="pre">finetuner.tailor.to_embedding_model</span></code>, which can be used as follows:</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--2-input--1" name="tab-set--2" type="radio"/><label class="tab-label" for="tab-set--2-input--1">PyTorch</label><div class="tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>  <span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
  <span class="kn">import</span> <span class="nn">torchvision</span>
  <span class="kn">import</span> <span class="nn">finetuner</span> <span class="k">as</span> <span class="nn">ft</span>

  <span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="k">class</span> <span class="nc">SimpleMLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
      <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
          <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">2048</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">l2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
          <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">))))</span>

  <span class="n">new_model</span> <span class="o">=</span> <span class="n">ft</span><span class="o">.</span><span class="n">tailor</span><span class="o">.</span><span class="n">to_embedding_model</span><span class="p">(</span>
      <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
      <span class="n">layer_name</span><span class="o">=</span><span class="s1">'adaptiveavgpool2d_173'</span><span class="p">,</span>
      <span class="n">freeze</span><span class="o">=</span><span class="p">[</span><span class="s1">'conv2d_1'</span><span class="p">,</span> <span class="s1">'batchnorm2d_2'</span><span class="p">],</span>  <span class="c1"># or set to True to freeze the entire model</span>
      <span class="n">bottleneck_net</span><span class="o">=</span><span class="n">SimpleMLP</span><span class="p">(),</span>
      <span class="n">input_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span>
  <span class="p">)</span>
</pre></div>
</div>
</div>
<input class="tab-input" id="tab-set--2-input--2" name="tab-set--2" type="radio"/><label class="tab-label" for="tab-set--2-input--2">Keras</label><div class="tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">finetuner</span> <span class="k">as</span> <span class="nn">ft</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">ResNet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">'imagenet'</span><span class="p">)</span>

<span class="n">bottleneck_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">bottleneck_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2048</span><span class="p">,)))</span>
<span class="n">bottleneck_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">bottleneck_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1024</span><span class="p">))</span>

<span class="n">new_model</span> <span class="o">=</span> <span class="n">ft</span><span class="o">.</span><span class="n">tailor</span><span class="o">.</span><span class="n">to_embedding_model</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">layer_name</span><span class="o">=</span><span class="s1">'avg_pool'</span><span class="p">,</span>
    <span class="n">freeze</span><span class="o">=</span><span class="p">[</span><span class="s1">'conv1_conv'</span><span class="p">,</span> <span class="s1">'conv1_bn'</span><span class="p">],</span>  <span class="c1"># or set to True to freeze the entire model</span>
    <span class="n">bottleneck_net</span><span class="o">=</span><span class="n">bottleneck_model</span><span class="p">,</span>
    <span class="n">input_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<input class="tab-input" id="tab-set--2-input--3" name="tab-set--2" type="radio"/><label class="tab-label" for="tab-set--2-input--3">Paddle</label><div class="tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">paddle</span>
<span class="kn">import</span> <span class="nn">paddle.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">finetuner</span> <span class="k">as</span> <span class="nn">ft</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">vision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">SimpleMLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>

      <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
          <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
    
<span class="n">new_model</span> <span class="o">=</span> <span class="n">ft</span><span class="o">.</span><span class="n">tailor</span><span class="o">.</span><span class="n">to_embedding_model</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">layer_name</span><span class="o">=</span><span class="s1">'adaptiveavgpool2d_173'</span><span class="p">,</span>
    <span class="n">freeze</span><span class="o">=</span><span class="p">[</span><span class="s1">'conv2d_1'</span><span class="p">,</span> <span class="s1">'batchnorm2d_2'</span><span class="p">],</span>  <span class="c1"># or set to True to freeze the entire model</span>
    <span class="n">bottleneck_net</span><span class="o">=</span><span class="n">SimpleMLP</span><span class="p">(),</span>
    <span class="n">input_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</li>
</ol>
<p>if you <code class="docutils literal notranslate"><span class="pre">display</span></code> the <code class="docutils literal notranslate"><span class="pre">new_model</span></code>, you’ll notice that the <code class="docutils literal notranslate"><span class="pre">fc</span></code> layer has been replaced with as <code class="docutils literal notranslate"><span class="pre">Identity</span></code>.
The layers you specified to <code class="docutils literal notranslate"><span class="pre">freeze</span></code> are not trainable anymore.
Last but not least, you attached a trainable bottleneck module and reduced the ouput dimensionality to <code class="docutils literal notranslate"><span class="pre">1024</span></code>.</p>
</section>
<section id="tips">
<h2>Tips<a class="headerlink" href="#tips" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>For PyTorch/Paddle models, having the correct <code class="docutils literal notranslate"><span class="pre">input_size</span></code> and <code class="docutils literal notranslate"><span class="pre">input_dtype</span></code> is fundamental to use <code class="docutils literal notranslate"><span class="pre">to_embedding_model</span></code> and <code class="docutils literal notranslate"><span class="pre">display</span></code>.</p></li>
<li><p>You can chop off layers and concat new layers afterward. To get the accurate layer name, you can first use <code class="docutils literal notranslate"><span class="pre">display</span></code> to list all layers.</p></li>
<li><p>Different frameworks may give different layer names. Often, PyTorch and Paddle layer names are consistent.</p></li>
</ul>
</section>
</section>

            </article>
            <footer>
                
                <div class="related-pages">
                    <a class="next-page" href="../labeler/">
                        <div class="page-info">
                            <div class="context">
                                <span>Next</span>
                            </div>
                            <div class="title">Labeler</div>
                        </div>
                        <svg>
                            <use href="#svg-arrow-right"></use>
                        </svg>
                    </a>
                    <a class="prev-page" href="../tuner/callbacks/">
                        <svg>
                            <use href="#svg-arrow-right"></use>
                        </svg>
                        <div class="page-info">
                            <div class="context">
                                <span>Previous</span>
                            </div>
                            
                            <div class="title">Callbacks</div>
                            
                        </div>
                    </a>
                </div>

                <div class="related-information sd-d-inline-flex">
                    <a href="https://jina.ai">Copyright &#169; Jina AI Limited. All rights reserved.</a>
                    Last updated on Dec 16, 2021.
                    <div class="social-btns">
                    <a class='social-btn' href="https://github.com/jina-ai/jina/" target="_blank"> <i class="fab fa-github"></i></a>
                    <a class='social-btn' href="https://slack.jina.ai" target="_blank"> <i class="fab fa-slack"></i></a>
                    <a class='social-btn' href="https://youtube.com/c/jina-ai" target="_blank"> <i class="fab fa-youtube"></i></a>
                    <a class='social-btn' href="https://twitter.com/JinaAI_" target="_blank"> <i class="fab fa-twitter"></i></a>
                    <a class='social-btn' href="https://www.linkedin.com/company/jinaai/" target="_blank"> <i class="fab fa-linkedin"></i></a>
                    </div>
                </div>
                
            </footer>
        </div>
        <aside class="toc-drawer">
            

            <div class="toc-sticky toc-scroll">
                
                <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
                </div>
                <div class="toc-tree-container">
                    <div class="toc-tree">
                        <ul>
<li><a class="reference internal" href="#">Tailor</a><ul>
<li><a class="reference internal" href="#display-model-summary"><code class="docutils literal notranslate"><span class="pre">display</span></code> model summary</a></li>
<li><a class="reference internal" href="#select-an-embedding-layer-as-your-model-output">Select an embedding layer as your model output.</a></li>
<li><a class="reference internal" href="#decide-your-freeze-strategy">Decide your <code class="docutils literal notranslate"><span class="pre">freeze</span></code> strategy.</a></li>
<li><a class="reference internal" href="#optional-attach-a-bottleneck-module">(optional) Attach a bottleneck module.</a></li>
<li><a class="reference internal" href="#tips">Tips</a></li>
</ul>
</li>
</ul>

                    </div>
                </div>
                
                <details id='jina-docbot' class="jina-doc-bot sd-sphinx-override sd-dropdown sd-card" v-bind:class="{ready: ready}">
    <summary class="sd-summary-title sd-card-header">
        <svg aria-hidden="true" class="sd-octicon sd-octicon-comment-discussion" height="1.0em"
             version="1.1" viewBox="0 0 16 16" width="1.0em">
            <path d="M1.5 2.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v5.5a.25.25 0 01-.25.25h-3.5a.75.75 0 00-.53.22L3.5 11.44V9.25a.75.75 0 00-.75-.75h-1a.25.25 0 01-.25-.25v-5.5zM1.75 1A1.75 1.75 0 000 2.75v5.5C0 9.216.784 10 1.75 10H2v1.543a1.457 1.457 0 002.487 1.03L7.061 10h3.189A1.75 1.75 0 0012 8.25v-5.5A1.75 1.75 0 0010.25 1h-8.5zM14.5 4.75a.25.25 0 00-.25-.25h-.5a.75.75 0 110-1.5h.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0114.25 12H14v1.543a1.457 1.457 0 01-2.487 1.03L9.22 12.28a.75.75 0 111.06-1.06l2.22 2.22v-2.19a.75.75 0 01.75-.75h1a.25.25 0 00.25-.25v-5.5z"
                  fill-rule="evenodd"></path>
        </svg>
        &nbsp; Ask our docs!
        <div class="sd-summary-down docutils">
            <svg aria-hidden="true" class="sd-octicon sd-octicon-chevron-down" height="1.5em"
                 version="1.1" viewBox="0 0 24 24" width="1.5em">
                <path d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"
                      fill-rule="evenodd"></path>
            </svg>
        </div>
        <div class="sd-summary-up docutils">
            <svg aria-hidden="true" class="sd-octicon sd-octicon-chevron-up" height="1.5em"
                 version="1.1" viewBox="0 0 24 24" width="1.5em">
                <path d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"
                      fill-rule="evenodd"></path>
            </svg>
        </div>
    </summary>
    <div class="sd-summary-content docutils">
        <div class="jina-doc-answer">
            <div class="jina-doc-answer-hint" v-if="qa_pairs.length===0">
                <p class="jina-doc-bot-help-text sd-font-weight-bold" v-if="!ready">Chat loading...<br><br>You can think of questions while our bot load. Try:</p>
                <p class="jina-doc-bot-help-text sd-font-weight-bold hidden-before-ready">You can ask questions about our docs. Try:</p>
                <ul class="example-question simple sd-font-weight-light">
                    <li><p>What is Tailor?</p></li>
                    <li><p>How can I freeze layers?</p></li>
                    <li><p>What is the input data format for finetuner?</p></li>
                </ul>
            </div>
            <div class="jina-doc-answer-dialog hidden-before-ready" v-else>
                <div v-for="qa in qa_pairs" class="qa-container">
                    <div v-if="qa.question" class="sd-text-right">
                        <div class="talk-bubble question-bubble">
                            <div class="talktext">
                                <p>${qa.question}</p>
                            </div>
                        </div>
                    </div>
                    <div class="talk-bubble answer-bubble">
                        <div class="talktext">
                            <p v-if="qa.answer">${qa.answer.text}</p>
                            <div v-else>
                                <svg height="10" width="40" class="loader">
                                    <circle class="dot" cx="10" cy="5" r="3"/>
                                    <circle class="dot" cx="20" cy="5" r="3"/>
                                    <circle class="dot" cx="30" cy="5" r="3"/>
                                </svg>
                            </div>
                        </div>
                        <a v-if="qa.answer && is_conn_broken" class="answer-reference" href="https://slack.jina.ai"
                           target="_blank">Report</a>
                        <div v-if="qa.answer && !is_conn_broken && qa.answer.uri" class="feedback-tooltip sd-d-flex-row">
                            <a class="answer-reference" :href="root_url + qa.answer.uri">Source</a>
                            <div class="sd-d-flex-row">
                                <div class="thumb-answer thumbup" v-show="qa.rating===null" style="margin: 0 6px" v-on:click="submit_rating(qa, true)">
                                    <svg aria-hidden="true" class="sd-octicon sd-octicon-thumbsup" height="1.0em"
                                         version="1.1" viewBox="0 0 16 16" width="1.0em">
                                        <path d="M8.834.066C7.494-.087 6.5 1.048 6.5 2.25v.5c0 1.329-.647 2.124-1.318 2.614-.328.24-.66.403-.918.508A1.75 1.75 0 002.75 5h-1A1.75 1.75 0 000 6.75v7.5C0 15.216.784 16 1.75 16h1a1.75 1.75 0 001.662-1.201c.525.075 1.067.229 1.725.415.152.043.31.088.475.133 1.154.32 2.54.653 4.388.653 1.706 0 2.97-.153 3.722-1.14.353-.463.537-1.042.668-1.672.118-.56.208-1.243.313-2.033l.04-.306c.25-1.869.265-3.318-.188-4.316a2.418 2.418 0 00-1.137-1.2C13.924 5.085 13.353 5 12.75 5h-1.422l.015-.113c.07-.518.157-1.17.157-1.637 0-.922-.151-1.719-.656-2.3-.51-.589-1.247-.797-2.01-.884zM4.5 13.3c.705.088 1.39.284 2.072.478l.441.125c1.096.305 2.334.598 3.987.598 1.794 0 2.28-.223 2.528-.549.147-.193.276-.505.394-1.07.105-.502.188-1.124.295-1.93l.04-.3c.25-1.882.189-2.933-.068-3.497a.922.922 0 00-.442-.48c-.208-.104-.52-.174-.997-.174H11c-.686 0-1.295-.577-1.206-1.336.023-.192.05-.39.076-.586.065-.488.13-.97.13-1.328 0-.809-.144-1.15-.288-1.316-.137-.158-.402-.304-1.048-.378C8.357 1.521 8 1.793 8 2.25v.5c0 1.922-.978 3.128-1.933 3.825a5.861 5.861 0 01-1.567.81V13.3zM2.75 6.5a.25.25 0 01.25.25v7.5a.25.25 0 01-.25.25h-1a.25.25 0 01-.25-.25v-7.5a.25.25 0 01.25-.25h1z"
                                              fill-rule="evenodd"></path>
                                    </svg>
                                </div>
                                <div class="thumb-answer thumbdown" v-show="qa.rating===null" v-on:click="submit_rating(qa, false)">
                                    <svg aria-hidden="true" class="sd-octicon sd-octicon-thumbsdown" height="1.0em"
                                         version="1.1" viewBox="0 0 16 16" width="1.0em">
                                        <path d="M7.083 15.986c1.34.153 2.334-.982 2.334-2.183v-.5c0-1.329.646-2.123 1.317-2.614.329-.24.66-.403.919-.508a1.75 1.75 0 001.514.872h1a1.75 1.75 0 001.75-1.75v-7.5a1.75 1.75 0 00-1.75-1.75h-1a1.75 1.75 0 00-1.662 1.2c-.525-.074-1.068-.228-1.726-.415L9.305.705C8.151.385 6.765.053 4.917.053c-1.706 0-2.97.152-3.722 1.139-.353.463-.537 1.042-.669 1.672C.41 3.424.32 4.108.214 4.897l-.04.306c-.25 1.869-.266 3.318.188 4.316.244.537.622.943 1.136 1.2.495.248 1.066.334 1.669.334h1.422l-.015.112c-.07.518-.157 1.17-.157 1.638 0 .921.151 1.718.655 2.299.512.589 1.248.797 2.011.884zm4.334-13.232c-.706-.089-1.39-.284-2.072-.479a63.914 63.914 0 00-.441-.125c-1.096-.304-2.335-.597-3.987-.597-1.794 0-2.28.222-2.529.548-.147.193-.275.505-.393 1.07-.105.502-.188 1.124-.295 1.93l-.04.3c-.25 1.882-.19 2.933.067 3.497a.921.921 0 00.443.48c.208.104.52.175.997.175h1.75c.685 0 1.295.577 1.205 1.335-.022.192-.049.39-.075.586-.066.488-.13.97-.13 1.329 0 .808.144 1.15.288 1.316.137.157.401.303 1.048.377.307.035.664-.237.664-.693v-.5c0-1.922.978-3.127 1.932-3.825a5.862 5.862 0 011.568-.809V2.754zm1.75 6.798a.25.25 0 01-.25-.25v-7.5a.25.25 0 01.25-.25h1a.25.25 0 01.25.25v7.5a.25.25 0 01-.25.25h-1z"
                                              fill-rule="evenodd"></path>
                                    </svg>
                                </div>
                            </div>
                        </div>
                    </div>

                </div>
            </div>


        </div>
        <div class="jina-doc-bot-controls sd-d-flex-row sd-border-1">
            <textarea v-model="cur_question" class="sd-border-0" maxlength="100" rows="3"
                      id="bot-input-question"
                      style="width: 100%"
                      placeholder="Just a moment, please ..."
                      :placeholder="'Type your question here'"
                      v-on:keyup.enter="submit_q"
                      disabled
                      :disabled="!ready"
                      :readonly="is_busy" autofocus></textarea>
            <button class="sd-sphinx-override sd-btn sd-text-wrap sd-btn-outline-primary sd-rounded-0 hidden-before-ready"
                    v-on:click="submit_q" v-show="cur_question.length>0 && !is_busy" id="bot-input-btn">
                <svg aria-hidden="true" class="sd-octicon sd-octicon-paper-airplane" height="1.0em"
                     version="1.1" viewBox="0 0 16 16" width="1.0em">
                    <path d="M1.592 2.712L2.38 7.25h4.87a.75.75 0 110 1.5H2.38l-.788 4.538L13.929 8 1.592 2.712zM.989 8L.064 2.68a1.341 1.341 0 011.85-1.462l13.402 5.744a1.13 1.13 0 010 2.076L1.913 14.782a1.341 1.341 0 01-1.85-1.463L.99 8z"
                          fill-rule="evenodd"></path>
                </svg>
            </button>
        </div>
        <div class="powered-by">
        </div>
    </div>
</details>
            </div>

            
        </aside>

    </div>
</div><script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/scripts/furo.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/tabs.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    <script>var server_address = 'https://finetuner-docsbot.jina.ai';</script>
    <script src="https://cdn.jsdelivr.net/npm/vue@2/dist/vue.min.js"></script>
    <script src="../../_static/docbot.js"></script>
    </body>
</html>